{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1wj1mWD64vJMUwjh_1jjFBHdGOpt010tr","authorship_tag":"ABX9TyMsY0AKcG+dq9nX66Zn3Wah"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Changing the directory**"],"metadata":{"id":"9YiR3W73N-79"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_ou-4-Mn9sg","executionInfo":{"status":"ok","timestamp":1674638901290,"user_tz":-210,"elapsed":311,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"66047f5e-d36e-48ec-9a0b-1664a6d86b8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1QjZ52EqSaXzJIHNRgjdB-qbPUcReg_SP/NasrAbadi/Miss-Match detection/StratifiedGroupFold\n"]}],"source":["cd '/content/drive/MyDrive/NasrAbadi/Miss-Match detection/StratifiedGroupFold'"]},{"cell_type":"markdown","source":["**Installing Required Packages**"],"metadata":{"id":"ODdeSoywOHAD"}},{"cell_type":"code","source":["!pip install scikeras\n","!pip install pyriemann\n","!pip install scikit-optimize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66p7ZZFooFz8","executionInfo":{"status":"ok","timestamp":1674638915053,"user_tz":-210,"elapsed":13480,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"b480af73-aa74-43a3-a4f4-d9a1d53d8ac4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikeras in /usr/local/lib/python3.8/dist-packages (0.10.0)\n","Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras) (21.3)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikeras) (1.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=0.21->scikeras) (3.0.9)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyriemann in /usr/local/lib/python3.8/dist-packages (0.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from pyriemann) (1.0.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pyriemann) (1.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyriemann) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pyriemann) (1.3.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pyriemann) (1.7.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pyriemann) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pyriemann) (2022.7)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pyriemann) (3.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->pyriemann) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-optimize\n","  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.2.0)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.7.3)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.0.2)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.21.6)\n","Collecting pyaml>=16.9\n","  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n","Installing collected packages: pyaml, scikit-optimize\n","Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"]}]},{"cell_type":"markdown","source":["**Loading the data**"],"metadata":{"id":"Etn2zlKpOVBE"}},{"cell_type":"code","source":["import numpy as np\n","X = np.load('X.npy')\n","Y = np.load('Y.npy')\n","\n","print(\"X Shape:\",X.shape)\n","print(\"Y shape:\",Y.shape)\n","print(Y)\n","import scipy.io\n","SegmentsPerSubject = scipy.io.loadmat('SegmentsPerSubject', mat_dtype=True)\n","SegmentsPerSubject = SegmentsPerSubject['SegmentsPerSubject']\n","SegmentsPerSubject = np.array(SegmentsPerSubject)\n","SegmentsPerSubject = SegmentsPerSubject.transpose()\n","print(\"shape Segments:\", SegmentsPerSubject.shape)\n","\n","Group =[]\n","for i in range(SegmentsPerSubject.shape[0]):\n","  for j in range(int(SegmentsPerSubject[i])):\n","    Group.append(i)\n","Group = np.array(Group)\n","Group = np.expand_dims(Group, axis=1)\n","print(Group)\n","print(\"Group shape is:\",Group.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwvmLU7XoEAl","executionInfo":{"status":"ok","timestamp":1674638916155,"user_tz":-210,"elapsed":1133,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"15a63061-0fa0-44a6-efad-d52f9e6a32bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X Shape: (7916, 1, 19, 1280)\n","Y shape: (7916,)\n","[0 0 0 ... 1 1 1]\n","shape Segments: (121, 1)\n","[[  0]\n"," [  0]\n"," [  0]\n"," ...\n"," [120]\n"," [120]\n"," [120]]\n","Group shape is: (7916, 1)\n"]}]},{"cell_type":"markdown","source":["**Change the channels to first**"],"metadata":{"id":"ATCe9tCpOnOT"}},{"cell_type":"code","source":["from tensorflow.keras import backend as K\n","K.set_image_data_format('channels_first')"],"metadata":{"id":"VGUtyufloIHt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Building the Model**"],"metadata":{"id":"rvGGG4VsOvPr"}},{"cell_type":"code","source":["from sklearn.utils.class_weight import compute_class_weight\n","from tensorflow.keras import utils as np_utils\n","from scikeras.wrappers import KerasClassifier\n","from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import SpatialDropout2D\n","from tensorflow.keras.regularizers import l1_l2\n","from tensorflow.keras.layers import Input, Flatten\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras import backend as K\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.optimizers import Adam\n","from keras.models import load_model\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import fbeta_score\n","import math\n","import gc\n","from numpy import mean\n","from numpy import std\n","from skopt import BayesSearchCV\n","from skopt.space import Real, Categorical, Integer\n","from sklearn.model_selection import cross_val_score\n","\n","def create_model(kernelLength = 32, nb_classes = 1, Chans = 19, Samples = 1280, \n","            dropoutRate = 0.5 , F1 = 8, \n","            D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n","  \n","  K.clear_session()\n","  gc.collect()\n","  if dropoutType == 'SpatialDropout2D':\n","      dropoutType = SpatialDropout2D\n","  elif dropoutType == 'Dropout':\n","      dropoutType = Dropout\n","  else:\n","      raise ValueError('dropoutType must be one of SpatialDropout2D '\n","                        'or Dropout, passed as a string.')\n","  \n","  input1   = Input(shape = (1, Chans, Samples))\n","\n","  ##################################################################\n","  block1       = Conv2D(F1, (1, kernelLength), padding = 'same',\n","                                  input_shape = (1, Chans, Samples),\n","                                  use_bias = False)(input1)\n","  block1       = BatchNormalization(axis = 1)(block1)\n","  block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n","                                  depth_multiplier = D,\n","                                  depthwise_constraint = max_norm(1.))(block1)\n","  block1       = BatchNormalization(axis = 1)(block1)\n","  block1       = Activation('elu')(block1)\n","  block1       = AveragePooling2D((1, 4))(block1)\n","  block1       = dropoutType(dropoutRate)(block1)\n","  \n","  block2       = SeparableConv2D(F2, (1, 16),\n","                                  use_bias = False, padding = 'same')(block1)\n","  block2       = BatchNormalization(axis = 1)(block2)\n","  block2       = Activation('elu')(block2)\n","  block2       = AveragePooling2D((1, 8))(block2)\n","  block2       = dropoutType(dropoutRate)(block2)\n","      \n","  flatten      = Flatten(name = 'flatten')(block2)\n","  \n","  dense        = Dense(nb_classes, name = 'dense', \n","                        kernel_constraint = max_norm(norm_rate))(flatten)\n","  sigmoid      = Activation('sigmoid', name = 'sigmoid')(dense)\n","  \n","  model        = Model(inputs=input1, outputs=sigmoid)\n","  model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n","  return model"],"metadata":{"id":"lXAWMcS6qHER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Calculating the accuracy and F-measure for each subject**"],"metadata":{"id":"gm7ngYfyOzuT"}},{"cell_type":"code","source":["def subject_classification(y_true, y_pred, group, calculate_type = 'max_vote'):  \n","  \"\"\"\n","  y_pred should be the output of 'model.predict' using 2 nodes in the dense layer and softmax activation.\n","  \"\"\"\n","  from pyriemann.utils.viz import plot_confusion_matrix\n","  from sklearn.metrics import fbeta_score\n","  probability = np.array(y_pred)\n","  prediction = y_pred.argmax(axis = -1)\n","  max_vote = []\n","  subject_traget = []\n","  j = 0\n","  unique, counts = np.unique(group, return_counts=True)\n","  mean_ = np.zeros([len(unique),2], dtype='float32')\n","  for i in range(len(unique)):\n","    for k in range(2):\n","      mean_[i][k] = np.mean(probability[j:j+counts[i]-1,k])\n","    c = np.bincount(prediction[j:j+counts[i]-1])\n","    max_vote.append(np.argmax(c))\n","    subject_traget.append(y_true[j])\n","    j = j + counts[i]\n","  mean_       = mean_.argmax(axis = -1)\n","  max_vote = np.array(max_vote)\n","  subject_traget = np.array(subject_traget)\n","  f2_max_vote      = fbeta_score(subject_traget, max_vote, beta=0.5, average='binary')\n","  f2_mean          = fbeta_score(subject_traget, mean_, beta=0.5, average='binary')\n","  acc_max_vote     = np.mean(max_vote == subject_traget)\n","  acc_mean         = np.mean(mean_ == subject_traget)\n","  if calculate_type == 'max_vote':\n","    names        = ['ADHD','Control']\n","    plt.figure(0)\n","    plot_confusion_matrix(subject_traget, max_vote, names, title = 'Max Vote Type')\n","    return acc_max_vote, f2_max_vote\n","  elif calculate_type == 'mean':\n","    names        = ['ADHD','Control']\n","    plt.figure(0)\n","    plot_confusion_matrix(subject_traget, mean_, names, title = 'Mean Type')\n","    return acc_mean, f2_mean\n","  else:\n","    raise ValueError('You have NOT entered an accurate type!')"],"metadata":{"id":"RUY4CBu0Puy_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Spliting the early stopping and test dataset**"],"metadata":{"id":"reVKqyFbPWGa"}},{"cell_type":"code","source":["group_kfold1 = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=2022)\n","# Test split ....\n","split_test = group_kfold1.split(X,Y,Group)\n","d_test = next(split_test)\n","X_tr = X[d_test[0]]\n","Y_tr = Y[d_test[0]]\n","X_test = X[d_test[1]]\n","Y_test = Y[d_test[1]]\n","Group_tr = Group[d_test[0]]\n","Group_test = Group[d_test[1]]\n","# Early stopping split ...\n","group_kfold2 = StratifiedGroupKFold(n_splits=18, shuffle=True, random_state=2022)\n","split_early = group_kfold2.split(X_tr,Y_tr,Group_tr)\n","d_early = next(split_early)\n","X_train = X_tr[d_early[0]]\n","Y_train = Y_tr[d_early[0]]\n","X_early = X_tr[d_early[1]]\n","Y_early = Y_tr[d_early[1]]\n","Group_train = Group_tr[d_early[0]]\n","Group_early = Group_tr[d_early[1]]\n","\n","del X,Y,X_tr,Y_tr, d_early,split_early,d_test, split_test, Group, Group_tr"],"metadata":{"id":"k7aMjOL_Piu6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Computing the Class Weight**"],"metadata":{"id":"CQ0HTDx-PkYQ"}},{"cell_type":"code","source":["### Compute Class_weight ###\n","def ClassWeight(y):\n","  class_weights = compute_class_weight(class_weight = \"balanced\",classes = np.unique(y), y = y)\n","  class_weights = dict(zip(np.unique(y), class_weights))\n","  class_weights[0] = int(10*round(class_weights[0],1))\n","  class_weights[1] = int(10*round(class_weights[1],1))\n","  class_weight = class_weights\n","  print(\"The Class Weight is:\",class_weight)\n","  return class_weight\n","class_weight = ClassWeight(Y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQgS95gZqM-B","executionInfo":{"status":"ok","timestamp":1674638922154,"user_tz":-210,"elapsed":1773,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"a6764154-b365-41c7-9c9e-8bba2f130abf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The Class Weight is: {0: 9, 1: 11}\n"]}]},{"cell_type":"code","source":["print(\"X_train shape:\",X_train.shape)\n","print(\"X_early shape:\",X_early.shape)\n","print(\"X_test shape:\",X_test.shape)\n","print(\"----------------------------\")\n","print(\"Y_train shape:\",Y_train.shape)\n","print(\"Y_early shape:\",Y_early.shape)\n","print(\"Y_test shape:\",Y_test.shape)\n","print('----------------------------')\n","print(\"Group_train shape:\",Group_train.shape)\n","print(\"Group_early shape:\",Group_early.shape)\n","print(\"Group_test shape:\",Group_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZmKZpLF-cv3A","executionInfo":{"status":"ok","timestamp":1674638922154,"user_tz":-210,"elapsed":8,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"67187682-0d86-4dc6-f13a-bd2d72c7efad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (6699, 1, 19, 1280)\n","X_early shape: (504, 1, 19, 1280)\n","X_test shape: (713, 1, 19, 1280)\n","----------------------------\n","Y_train shape: (6699,)\n","Y_early shape: (504,)\n","Y_test shape: (713,)\n","----------------------------\n","Group_train shape: (6699, 1)\n","Group_early shape: (504, 1)\n","Group_test shape: (713, 1)\n"]}]},{"cell_type":"markdown","source":["**Defining the Bayesian Optimization using the search space and defined model**"],"metadata":{"id":"caMBkWSHQDOY"}},{"cell_type":"code","source":["es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n","callbacks = [es]\n","# KerasClassifier Defining \n","\n","model = KerasClassifier(model=create_model, verbose = 2,shuffle=True,\n","                        epochs=100,batch_size=32,fit__validation_data =(X_early, Y_early),\n","                        class_weight=class_weight,callbacks=callbacks)\n","#Search space\n","search_space = {'model__F1': Categorical([8, 16]),\n","                'model__F2': Categorical([16, 32]),\n","                'model__kernelLength': Categorical([32, 64, 128, 256, 512]),\n","                'model__norm_rate': Categorical([0.5, 1.0, 5.0, 10.0])}\n","\n","search = BayesSearchCV(estimator=model, search_spaces=search_space,\n","                       n_iter=10,cv=5, n_jobs=1, verbose=True)"],"metadata":{"id":"vPBDQNX-qd8A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Fitting the model to find the optimal hyper-parameters**"],"metadata":{"id":"L1CjWhl5QUQo"}},{"cell_type":"code","source":["search_result = search.fit(X_train, y=Y_train, groups=Group_train)\n","means = search_result.cv_results_['mean_test_score']\n","stds = search_result.cv_results_['std_test_score']\n","params = search_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n","print(\"The Best Score:\",search.best_score_)\n","print(\"The Best Params:\",search.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YTG6G14_z9Wa","executionInfo":{"status":"ok","timestamp":1674642231928,"user_tz":-210,"elapsed":3309780,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"28a8554e-34d5-473d-ca6c-4d61b8916965"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","Epoch 1/100\n","168/168 - 13s - loss: 4.5206 - accuracy: 0.7832 - val_loss: 0.6826 - val_accuracy: 0.5893 - 13s/epoch - 74ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.4693 - accuracy: 0.9472 - val_loss: 1.3214 - val_accuracy: 0.5417 - 3s/epoch - 16ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 0.7936 - accuracy: 0.9711 - val_loss: 1.2181 - val_accuracy: 0.5655 - 3s/epoch - 16ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.4201 - accuracy: 0.9871 - val_loss: 1.1296 - val_accuracy: 0.5972 - 3s/epoch - 17ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.3315 - accuracy: 0.9890 - val_loss: 2.0124 - val_accuracy: 0.5337 - 3s/epoch - 17ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.3906 - accuracy: 0.9877 - val_loss: 1.4974 - val_accuracy: 0.5556 - 3s/epoch - 17ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.2188 - accuracy: 0.9938 - val_loss: 0.7898 - val_accuracy: 0.8095 - 3s/epoch - 17ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.1859 - accuracy: 0.9942 - val_loss: 1.1668 - val_accuracy: 0.7004 - 3s/epoch - 17ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.2155 - accuracy: 0.9937 - val_loss: 1.5717 - val_accuracy: 0.8036 - 3s/epoch - 17ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.1293 - accuracy: 0.9963 - val_loss: 2.4096 - val_accuracy: 0.4782 - 3s/epoch - 17ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.0790 - accuracy: 0.9985 - val_loss: 2.6248 - val_accuracy: 0.5675 - 3s/epoch - 18ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.0708 - accuracy: 0.9981 - val_loss: 2.0751 - val_accuracy: 0.4841 - 3s/epoch - 17ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.1092 - accuracy: 0.9970 - val_loss: 1.9739 - val_accuracy: 0.6667 - 3s/epoch - 17ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.1168 - accuracy: 0.9963 - val_loss: 2.7217 - val_accuracy: 0.5000 - 3s/epoch - 17ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.0879 - accuracy: 0.9976 - val_loss: 2.8617 - val_accuracy: 0.4762 - 3s/epoch - 17ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.1530 - accuracy: 0.9940 - val_loss: 2.1560 - val_accuracy: 0.4821 - 3s/epoch - 18ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 327ms/epoch - 8ms/step\n","Epoch 1/100\n","168/168 - 4s - loss: 4.8120 - accuracy: 0.7714 - val_loss: 0.6567 - val_accuracy: 0.5377 - 4s/epoch - 22ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.6396 - accuracy: 0.9416 - val_loss: 0.5961 - val_accuracy: 0.8651 - 3s/epoch - 17ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 0.7402 - accuracy: 0.9748 - val_loss: 0.6953 - val_accuracy: 0.8750 - 3s/epoch - 17ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.4738 - accuracy: 0.9851 - val_loss: 1.0045 - val_accuracy: 0.5456 - 3s/epoch - 17ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.3974 - accuracy: 0.9873 - val_loss: 0.5740 - val_accuracy: 0.8214 - 3s/epoch - 17ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.4134 - accuracy: 0.9879 - val_loss: 0.6322 - val_accuracy: 0.7917 - 3s/epoch - 17ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.2299 - accuracy: 0.9931 - val_loss: 0.7950 - val_accuracy: 0.7619 - 3s/epoch - 17ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.3319 - accuracy: 0.9903 - val_loss: 0.5737 - val_accuracy: 0.8353 - 3s/epoch - 17ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.1947 - accuracy: 0.9950 - val_loss: 0.7181 - val_accuracy: 0.8790 - 3s/epoch - 17ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.2948 - accuracy: 0.9907 - val_loss: 0.8909 - val_accuracy: 0.7401 - 3s/epoch - 17ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.2367 - accuracy: 0.9925 - val_loss: 0.7430 - val_accuracy: 0.8790 - 3s/epoch - 17ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.2462 - accuracy: 0.9918 - val_loss: 0.8706 - val_accuracy: 0.8849 - 3s/epoch - 17ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.1208 - accuracy: 0.9968 - val_loss: 3.0071 - val_accuracy: 0.5238 - 3s/epoch - 17ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.2453 - accuracy: 0.9925 - val_loss: 0.9010 - val_accuracy: 0.8671 - 3s/epoch - 17ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.1646 - accuracy: 0.9933 - val_loss: 1.3891 - val_accuracy: 0.7024 - 3s/epoch - 17ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.1008 - accuracy: 0.9972 - val_loss: 0.7545 - val_accuracy: 0.8770 - 3s/epoch - 17ms/step\n","Epoch 17/100\n","168/168 - 3s - loss: 0.1675 - accuracy: 0.9951 - val_loss: 0.8217 - val_accuracy: 0.8750 - 3s/epoch - 17ms/step\n","Epoch 18/100\n","168/168 - 3s - loss: 0.0906 - accuracy: 0.9974 - val_loss: 1.0615 - val_accuracy: 0.8849 - 3s/epoch - 17ms/step\n","Epoch 19/100\n","168/168 - 3s - loss: 0.1128 - accuracy: 0.9965 - val_loss: 0.6516 - val_accuracy: 0.8433 - 3s/epoch - 17ms/step\n","Epoch 20/100\n","168/168 - 3s - loss: 0.0456 - accuracy: 0.9987 - val_loss: 0.3742 - val_accuracy: 0.8948 - 3s/epoch - 17ms/step\n","Epoch 21/100\n","168/168 - 3s - loss: 0.1571 - accuracy: 0.9957 - val_loss: 0.9841 - val_accuracy: 0.8810 - 3s/epoch - 17ms/step\n","Epoch 22/100\n","168/168 - 3s - loss: 0.0999 - accuracy: 0.9970 - val_loss: 1.2798 - val_accuracy: 0.8889 - 3s/epoch - 16ms/step\n","Epoch 23/100\n","168/168 - 3s - loss: 0.1184 - accuracy: 0.9959 - val_loss: 0.7053 - val_accuracy: 0.8671 - 3s/epoch - 17ms/step\n","Epoch 24/100\n","168/168 - 3s - loss: 0.1349 - accuracy: 0.9955 - val_loss: 1.5577 - val_accuracy: 0.8849 - 3s/epoch - 17ms/step\n","Epoch 25/100\n","168/168 - 3s - loss: 0.0950 - accuracy: 0.9965 - val_loss: 0.8937 - val_accuracy: 0.8849 - 3s/epoch - 17ms/step\n","Epoch 26/100\n","168/168 - 3s - loss: 0.1016 - accuracy: 0.9959 - val_loss: 0.6710 - val_accuracy: 0.8671 - 3s/epoch - 17ms/step\n","Epoch 27/100\n","168/168 - 3s - loss: 0.0783 - accuracy: 0.9972 - val_loss: 0.7524 - val_accuracy: 0.8770 - 3s/epoch - 16ms/step\n","Epoch 28/100\n","168/168 - 3s - loss: 0.0561 - accuracy: 0.9981 - val_loss: 0.8541 - val_accuracy: 0.8829 - 3s/epoch - 16ms/step\n","Epoch 29/100\n","168/168 - 3s - loss: 0.1222 - accuracy: 0.9966 - val_loss: 0.5151 - val_accuracy: 0.8849 - 3s/epoch - 17ms/step\n","Epoch 30/100\n","168/168 - 3s - loss: 0.0458 - accuracy: 0.9985 - val_loss: 0.9579 - val_accuracy: 0.8849 - 3s/epoch - 19ms/step\n","Epoch 31/100\n","168/168 - 3s - loss: 0.1098 - accuracy: 0.9966 - val_loss: 0.8865 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 32/100\n","168/168 - 3s - loss: 0.1033 - accuracy: 0.9965 - val_loss: 0.5411 - val_accuracy: 0.8730 - 3s/epoch - 17ms/step\n","Epoch 33/100\n","168/168 - 3s - loss: 0.1216 - accuracy: 0.9966 - val_loss: 0.7821 - val_accuracy: 0.8869 - 3s/epoch - 17ms/step\n","Epoch 34/100\n","168/168 - 3s - loss: 0.0778 - accuracy: 0.9976 - val_loss: 1.1614 - val_accuracy: 0.8869 - 3s/epoch - 17ms/step\n","Epoch 35/100\n","168/168 - 3s - loss: 0.0829 - accuracy: 0.9966 - val_loss: 0.8795 - val_accuracy: 0.8849 - 3s/epoch - 17ms/step\n","Epoch 35: early stopping\n","42/42 - 0s - 247ms/epoch - 6ms/step\n","Epoch 1/100\n","168/168 - 4s - loss: 5.1485 - accuracy: 0.7298 - val_loss: 0.5915 - val_accuracy: 0.7004 - 4s/epoch - 23ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.5060 - accuracy: 0.9489 - val_loss: 1.8222 - val_accuracy: 0.4206 - 3s/epoch - 17ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 0.6402 - accuracy: 0.9791 - val_loss: 1.2763 - val_accuracy: 0.8631 - 3s/epoch - 17ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.4785 - accuracy: 0.9851 - val_loss: 1.2334 - val_accuracy: 0.7579 - 3s/epoch - 17ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.2573 - accuracy: 0.9920 - val_loss: 1.3564 - val_accuracy: 0.8512 - 3s/epoch - 17ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.2065 - accuracy: 0.9935 - val_loss: 2.6205 - val_accuracy: 0.5556 - 3s/epoch - 17ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.2416 - accuracy: 0.9909 - val_loss: 4.1745 - val_accuracy: 0.4782 - 3s/epoch - 17ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.2780 - accuracy: 0.9925 - val_loss: 5.2869 - val_accuracy: 0.2321 - 3s/epoch - 17ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.1529 - accuracy: 0.9957 - val_loss: 1.9713 - val_accuracy: 0.6429 - 3s/epoch - 17ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.1607 - accuracy: 0.9953 - val_loss: 3.0085 - val_accuracy: 0.5298 - 3s/epoch - 17ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.1209 - accuracy: 0.9950 - val_loss: 1.7237 - val_accuracy: 0.7004 - 3s/epoch - 17ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.0771 - accuracy: 0.9983 - val_loss: 2.7641 - val_accuracy: 0.5397 - 3s/epoch - 17ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.1128 - accuracy: 0.9961 - val_loss: 1.7644 - val_accuracy: 0.8373 - 3s/epoch - 17ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.2319 - accuracy: 0.9912 - val_loss: 3.0886 - val_accuracy: 0.2877 - 3s/epoch - 17ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.0854 - accuracy: 0.9978 - val_loss: 1.8316 - val_accuracy: 0.8770 - 3s/epoch - 17ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.0957 - accuracy: 0.9966 - val_loss: 2.0131 - val_accuracy: 0.6468 - 3s/epoch - 17ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 262ms/epoch - 6ms/step\n","Epoch 1/100\n","168/168 - 4s - loss: 4.4693 - accuracy: 0.7888 - val_loss: 0.3602 - val_accuracy: 0.8869 - 4s/epoch - 22ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.4440 - accuracy: 0.9496 - val_loss: 0.3896 - val_accuracy: 0.8869 - 3s/epoch - 16ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 0.7336 - accuracy: 0.9752 - val_loss: 0.6967 - val_accuracy: 0.8810 - 3s/epoch - 16ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.5017 - accuracy: 0.9841 - val_loss: 1.3046 - val_accuracy: 0.8869 - 3s/epoch - 16ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.3263 - accuracy: 0.9899 - val_loss: 1.1404 - val_accuracy: 0.8869 - 3s/epoch - 16ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.2262 - accuracy: 0.9937 - val_loss: 1.0379 - val_accuracy: 0.8730 - 3s/epoch - 16ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.1848 - accuracy: 0.9953 - val_loss: 1.1784 - val_accuracy: 0.8393 - 3s/epoch - 17ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.1652 - accuracy: 0.9959 - val_loss: 1.4058 - val_accuracy: 0.8810 - 3s/epoch - 16ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.2098 - accuracy: 0.9933 - val_loss: 1.6561 - val_accuracy: 0.8869 - 3s/epoch - 16ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.1395 - accuracy: 0.9951 - val_loss: 1.6866 - val_accuracy: 0.6627 - 3s/epoch - 16ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.0957 - accuracy: 0.9974 - val_loss: 1.8391 - val_accuracy: 0.8869 - 3s/epoch - 17ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.1026 - accuracy: 0.9972 - val_loss: 1.6292 - val_accuracy: 0.8849 - 3s/epoch - 17ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.0703 - accuracy: 0.9983 - val_loss: 1.5997 - val_accuracy: 0.8849 - 3s/epoch - 16ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.0772 - accuracy: 0.9978 - val_loss: 1.7487 - val_accuracy: 0.8869 - 3s/epoch - 17ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.0401 - accuracy: 0.9991 - val_loss: 1.9996 - val_accuracy: 0.8829 - 3s/epoch - 16ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.0742 - accuracy: 0.9983 - val_loss: 1.6826 - val_accuracy: 0.8869 - 3s/epoch - 16ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 251ms/epoch - 6ms/step\n","Epoch 1/100\n","168/168 - 4s - loss: 5.1612 - accuracy: 0.7194 - val_loss: 0.4448 - val_accuracy: 0.9028 - 4s/epoch - 22ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.8185 - accuracy: 0.9353 - val_loss: 0.9226 - val_accuracy: 0.9028 - 3s/epoch - 17ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 0.7117 - accuracy: 0.9769 - val_loss: 2.1689 - val_accuracy: 0.5873 - 3s/epoch - 16ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.4454 - accuracy: 0.9871 - val_loss: 2.5550 - val_accuracy: 0.5099 - 3s/epoch - 17ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.2802 - accuracy: 0.9933 - val_loss: 2.7008 - val_accuracy: 0.5655 - 3s/epoch - 17ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.3472 - accuracy: 0.9909 - val_loss: 3.3420 - val_accuracy: 0.4524 - 3s/epoch - 17ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.2412 - accuracy: 0.9920 - val_loss: 2.6135 - val_accuracy: 0.9028 - 3s/epoch - 17ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.1937 - accuracy: 0.9942 - val_loss: 2.8495 - val_accuracy: 0.3790 - 3s/epoch - 17ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.3040 - accuracy: 0.9909 - val_loss: 2.2932 - val_accuracy: 0.8889 - 3s/epoch - 17ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.1436 - accuracy: 0.9946 - val_loss: 2.2916 - val_accuracy: 0.7599 - 3s/epoch - 17ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.0977 - accuracy: 0.9981 - val_loss: 2.3433 - val_accuracy: 0.8869 - 3s/epoch - 17ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.1529 - accuracy: 0.9950 - val_loss: 2.1750 - val_accuracy: 0.8889 - 3s/epoch - 17ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.0853 - accuracy: 0.9979 - val_loss: 2.3592 - val_accuracy: 0.8671 - 3s/epoch - 17ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.0989 - accuracy: 0.9972 - val_loss: 2.5263 - val_accuracy: 0.9008 - 3s/epoch - 17ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.0921 - accuracy: 0.9970 - val_loss: 2.3130 - val_accuracy: 0.8889 - 3s/epoch - 17ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.0632 - accuracy: 0.9978 - val_loss: 2.5866 - val_accuracy: 0.6389 - 3s/epoch - 17ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 261ms/epoch - 6ms/step\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","Epoch 1/100\n","168/168 - 7s - loss: 4.6953 - accuracy: 0.7755 - val_loss: 1.0333 - val_accuracy: 0.5377 - 7s/epoch - 41ms/step\n","Epoch 2/100\n","168/168 - 6s - loss: 2.0077 - accuracy: 0.9244 - val_loss: 1.7313 - val_accuracy: 0.4425 - 6s/epoch - 34ms/step\n","Epoch 3/100\n","168/168 - 6s - loss: 1.1085 - accuracy: 0.9591 - val_loss: 1.5953 - val_accuracy: 0.6528 - 6s/epoch - 34ms/step\n","Epoch 4/100\n","168/168 - 6s - loss: 0.9337 - accuracy: 0.9675 - val_loss: 1.8710 - val_accuracy: 0.6369 - 6s/epoch - 34ms/step\n","Epoch 5/100\n","168/168 - 6s - loss: 0.7595 - accuracy: 0.9728 - val_loss: 4.1063 - val_accuracy: 0.4881 - 6s/epoch - 34ms/step\n","Epoch 6/100\n","168/168 - 6s - loss: 0.5331 - accuracy: 0.9810 - val_loss: 0.5293 - val_accuracy: 0.7679 - 6s/epoch - 35ms/step\n","Epoch 7/100\n","168/168 - 6s - loss: 0.3485 - accuracy: 0.9879 - val_loss: 1.2113 - val_accuracy: 0.6290 - 6s/epoch - 35ms/step\n","Epoch 8/100\n","168/168 - 6s - loss: 0.4679 - accuracy: 0.9843 - val_loss: 2.0548 - val_accuracy: 0.6270 - 6s/epoch - 34ms/step\n","Epoch 9/100\n","168/168 - 6s - loss: 0.2826 - accuracy: 0.9905 - val_loss: 1.2775 - val_accuracy: 0.6310 - 6s/epoch - 34ms/step\n","Epoch 10/100\n","168/168 - 6s - loss: 0.2731 - accuracy: 0.9903 - val_loss: 1.1380 - val_accuracy: 0.6409 - 6s/epoch - 35ms/step\n","Epoch 11/100\n","168/168 - 6s - loss: 0.3525 - accuracy: 0.9882 - val_loss: 1.8936 - val_accuracy: 0.5516 - 6s/epoch - 35ms/step\n","Epoch 12/100\n","168/168 - 6s - loss: 0.2347 - accuracy: 0.9910 - val_loss: 1.3628 - val_accuracy: 0.6448 - 6s/epoch - 34ms/step\n","Epoch 13/100\n","168/168 - 6s - loss: 0.2233 - accuracy: 0.9909 - val_loss: 0.8472 - val_accuracy: 0.7024 - 6s/epoch - 34ms/step\n","Epoch 14/100\n","168/168 - 6s - loss: 0.1150 - accuracy: 0.9961 - val_loss: 0.6493 - val_accuracy: 0.7897 - 6s/epoch - 34ms/step\n","Epoch 15/100\n","168/168 - 6s - loss: 0.1262 - accuracy: 0.9963 - val_loss: 0.8460 - val_accuracy: 0.7163 - 6s/epoch - 35ms/step\n","Epoch 16/100\n","168/168 - 6s - loss: 0.3049 - accuracy: 0.9903 - val_loss: 1.4224 - val_accuracy: 0.6786 - 6s/epoch - 35ms/step\n","Epoch 17/100\n","168/168 - 6s - loss: 0.1390 - accuracy: 0.9955 - val_loss: 2.5579 - val_accuracy: 0.5694 - 6s/epoch - 36ms/step\n","Epoch 18/100\n","168/168 - 6s - loss: 0.0702 - accuracy: 0.9979 - val_loss: 0.7996 - val_accuracy: 0.7877 - 6s/epoch - 35ms/step\n","Epoch 19/100\n","168/168 - 6s - loss: 0.2266 - accuracy: 0.9927 - val_loss: 0.8247 - val_accuracy: 0.8968 - 6s/epoch - 35ms/step\n","Epoch 20/100\n","168/168 - 6s - loss: 0.1077 - accuracy: 0.9966 - val_loss: 0.5810 - val_accuracy: 0.8571 - 6s/epoch - 34ms/step\n","Epoch 21/100\n","168/168 - 6s - loss: 0.1400 - accuracy: 0.9951 - val_loss: 0.6104 - val_accuracy: 0.8690 - 6s/epoch - 35ms/step\n","Epoch 21: early stopping\n","42/42 - 1s - 771ms/epoch - 18ms/step\n","Epoch 1/100\n","168/168 - 7s - loss: 5.0053 - accuracy: 0.7505 - val_loss: 0.7669 - val_accuracy: 0.5020 - 7s/epoch - 40ms/step\n","Epoch 2/100\n","168/168 - 6s - loss: 2.4177 - accuracy: 0.9007 - val_loss: 1.1362 - val_accuracy: 0.5060 - 6s/epoch - 34ms/step\n","Epoch 3/100\n","168/168 - 6s - loss: 1.2672 - accuracy: 0.9526 - val_loss: 6.8154 - val_accuracy: 0.3075 - 6s/epoch - 33ms/step\n","Epoch 4/100\n","168/168 - 6s - loss: 0.7136 - accuracy: 0.9750 - val_loss: 5.1084 - val_accuracy: 0.3472 - 6s/epoch - 34ms/step\n","Epoch 5/100\n","168/168 - 6s - loss: 0.5415 - accuracy: 0.9802 - val_loss: 4.1260 - val_accuracy: 0.4464 - 6s/epoch - 34ms/step\n","Epoch 6/100\n","168/168 - 6s - loss: 0.4167 - accuracy: 0.9877 - val_loss: 2.3395 - val_accuracy: 0.6448 - 6s/epoch - 34ms/step\n","Epoch 7/100\n","168/168 - 6s - loss: 0.4402 - accuracy: 0.9830 - val_loss: 2.4951 - val_accuracy: 0.6290 - 6s/epoch - 34ms/step\n","Epoch 8/100\n","168/168 - 6s - loss: 0.4092 - accuracy: 0.9873 - val_loss: 3.4144 - val_accuracy: 0.5179 - 6s/epoch - 34ms/step\n","Epoch 9/100\n","168/168 - 6s - loss: 0.2540 - accuracy: 0.9920 - val_loss: 2.0006 - val_accuracy: 0.7202 - 6s/epoch - 35ms/step\n","Epoch 10/100\n","168/168 - 6s - loss: 0.2402 - accuracy: 0.9937 - val_loss: 3.7901 - val_accuracy: 0.4802 - 6s/epoch - 34ms/step\n","Epoch 11/100\n","168/168 - 6s - loss: 0.2348 - accuracy: 0.9920 - val_loss: 7.9216 - val_accuracy: 0.3690 - 6s/epoch - 35ms/step\n","Epoch 12/100\n","168/168 - 6s - loss: 0.2838 - accuracy: 0.9910 - val_loss: 6.1386 - val_accuracy: 0.3571 - 6s/epoch - 34ms/step\n","Epoch 13/100\n","168/168 - 6s - loss: 0.2352 - accuracy: 0.9931 - val_loss: 9.1021 - val_accuracy: 0.3512 - 6s/epoch - 34ms/step\n","Epoch 14/100\n","168/168 - 6s - loss: 0.2373 - accuracy: 0.9922 - val_loss: 3.7059 - val_accuracy: 0.4444 - 6s/epoch - 35ms/step\n","Epoch 15/100\n","168/168 - 6s - loss: 0.1623 - accuracy: 0.9944 - val_loss: 2.2402 - val_accuracy: 0.5714 - 6s/epoch - 34ms/step\n","Epoch 16/100\n","168/168 - 6s - loss: 0.2145 - accuracy: 0.9920 - val_loss: 4.4415 - val_accuracy: 0.3770 - 6s/epoch - 34ms/step\n","Epoch 16: early stopping\n","42/42 - 1s - 572ms/epoch - 14ms/step\n","Epoch 1/100\n","168/168 - 7s - loss: 5.8319 - accuracy: 0.6936 - val_loss: 0.3339 - val_accuracy: 0.9008 - 7s/epoch - 40ms/step\n","Epoch 2/100\n","168/168 - 6s - loss: 2.8346 - accuracy: 0.8880 - val_loss: 0.8731 - val_accuracy: 0.4583 - 6s/epoch - 35ms/step\n","Epoch 3/100\n","168/168 - 6s - loss: 1.4661 - accuracy: 0.9500 - val_loss: 0.5148 - val_accuracy: 0.8393 - 6s/epoch - 35ms/step\n","Epoch 4/100\n","168/168 - 6s - loss: 0.8861 - accuracy: 0.9690 - val_loss: 0.5769 - val_accuracy: 0.8611 - 6s/epoch - 35ms/step\n","Epoch 5/100\n","168/168 - 6s - loss: 0.6381 - accuracy: 0.9770 - val_loss: 0.7903 - val_accuracy: 0.8135 - 6s/epoch - 35ms/step\n","Epoch 6/100\n","168/168 - 6s - loss: 0.4350 - accuracy: 0.9845 - val_loss: 0.7478 - val_accuracy: 0.8651 - 6s/epoch - 35ms/step\n","Epoch 7/100\n","168/168 - 6s - loss: 0.3271 - accuracy: 0.9881 - val_loss: 0.7482 - val_accuracy: 0.8869 - 6s/epoch - 35ms/step\n","Epoch 8/100\n","168/168 - 6s - loss: 0.3840 - accuracy: 0.9879 - val_loss: 1.2114 - val_accuracy: 0.6429 - 6s/epoch - 34ms/step\n","Epoch 9/100\n","168/168 - 6s - loss: 0.3054 - accuracy: 0.9901 - val_loss: 1.8173 - val_accuracy: 0.5972 - 6s/epoch - 35ms/step\n","Epoch 10/100\n","168/168 - 6s - loss: 0.2098 - accuracy: 0.9927 - val_loss: 1.9282 - val_accuracy: 0.6548 - 6s/epoch - 35ms/step\n","Epoch 11/100\n","168/168 - 6s - loss: 0.1690 - accuracy: 0.9940 - val_loss: 1.4898 - val_accuracy: 0.8829 - 6s/epoch - 34ms/step\n","Epoch 12/100\n","168/168 - 6s - loss: 0.2355 - accuracy: 0.9925 - val_loss: 2.0931 - val_accuracy: 0.6944 - 6s/epoch - 34ms/step\n","Epoch 13/100\n","168/168 - 6s - loss: 0.2004 - accuracy: 0.9927 - val_loss: 1.3759 - val_accuracy: 0.8810 - 6s/epoch - 35ms/step\n","Epoch 14/100\n","168/168 - 6s - loss: 0.1311 - accuracy: 0.9953 - val_loss: 2.0776 - val_accuracy: 0.8571 - 6s/epoch - 34ms/step\n","Epoch 15/100\n","168/168 - 6s - loss: 0.2550 - accuracy: 0.9933 - val_loss: 1.6028 - val_accuracy: 0.8353 - 6s/epoch - 34ms/step\n","Epoch 16/100\n","168/168 - 6s - loss: 0.1752 - accuracy: 0.9933 - val_loss: 1.6829 - val_accuracy: 0.8790 - 6s/epoch - 34ms/step\n","Epoch 16: early stopping\n","42/42 - 1s - 570ms/epoch - 14ms/step\n","Epoch 1/100\n","168/168 - 7s - loss: 5.3493 - accuracy: 0.7236 - val_loss: 0.5274 - val_accuracy: 0.6111 - 7s/epoch - 40ms/step\n","Epoch 2/100\n","168/168 - 6s - loss: 1.8914 - accuracy: 0.9386 - val_loss: 1.2194 - val_accuracy: 0.4643 - 6s/epoch - 34ms/step\n","Epoch 3/100\n","168/168 - 6s - loss: 1.3254 - accuracy: 0.9561 - val_loss: 1.4262 - val_accuracy: 0.5099 - 6s/epoch - 34ms/step\n","Epoch 4/100\n","168/168 - 6s - loss: 1.0066 - accuracy: 0.9687 - val_loss: 3.3526 - val_accuracy: 0.1865 - 6s/epoch - 34ms/step\n","Epoch 5/100\n","168/168 - 6s - loss: 0.7774 - accuracy: 0.9707 - val_loss: 1.5739 - val_accuracy: 0.6270 - 6s/epoch - 34ms/step\n","Epoch 6/100\n","168/168 - 6s - loss: 0.5816 - accuracy: 0.9793 - val_loss: 2.8423 - val_accuracy: 0.2460 - 6s/epoch - 35ms/step\n","Epoch 7/100\n","168/168 - 6s - loss: 0.5010 - accuracy: 0.9817 - val_loss: 1.6138 - val_accuracy: 0.8909 - 6s/epoch - 35ms/step\n","Epoch 8/100\n","168/168 - 6s - loss: 0.3607 - accuracy: 0.9884 - val_loss: 1.5657 - val_accuracy: 0.8849 - 6s/epoch - 35ms/step\n","Epoch 9/100\n","168/168 - 6s - loss: 0.4155 - accuracy: 0.9853 - val_loss: 4.2595 - val_accuracy: 0.2520 - 6s/epoch - 35ms/step\n","Epoch 10/100\n","168/168 - 6s - loss: 0.3027 - accuracy: 0.9892 - val_loss: 1.7186 - val_accuracy: 0.8690 - 6s/epoch - 35ms/step\n","Epoch 11/100\n","168/168 - 6s - loss: 0.2412 - accuracy: 0.9909 - val_loss: 1.7212 - val_accuracy: 0.8690 - 6s/epoch - 35ms/step\n","Epoch 12/100\n","168/168 - 6s - loss: 0.2670 - accuracy: 0.9907 - val_loss: 1.8931 - val_accuracy: 0.8869 - 6s/epoch - 36ms/step\n","Epoch 13/100\n","168/168 - 6s - loss: 0.2199 - accuracy: 0.9937 - val_loss: 1.8596 - val_accuracy: 0.6567 - 6s/epoch - 35ms/step\n","Epoch 14/100\n","168/168 - 6s - loss: 0.1114 - accuracy: 0.9966 - val_loss: 3.5669 - val_accuracy: 0.2976 - 6s/epoch - 34ms/step\n","Epoch 15/100\n","168/168 - 6s - loss: 0.1931 - accuracy: 0.9942 - val_loss: 1.8983 - val_accuracy: 0.8770 - 6s/epoch - 35ms/step\n","Epoch 16/100\n","168/168 - 6s - loss: 0.2175 - accuracy: 0.9914 - val_loss: 7.6911 - val_accuracy: 0.1587 - 6s/epoch - 34ms/step\n","Epoch 16: early stopping\n","42/42 - 1s - 564ms/epoch - 13ms/step\n","Epoch 1/100\n","168/168 - 7s - loss: 5.7242 - accuracy: 0.6929 - val_loss: 0.5267 - val_accuracy: 0.7996 - 7s/epoch - 40ms/step\n","Epoch 2/100\n","168/168 - 6s - loss: 2.4941 - accuracy: 0.8996 - val_loss: 0.6668 - val_accuracy: 0.7659 - 6s/epoch - 35ms/step\n","Epoch 3/100\n","168/168 - 6s - loss: 1.4741 - accuracy: 0.9431 - val_loss: 0.9946 - val_accuracy: 0.7004 - 6s/epoch - 35ms/step\n","Epoch 4/100\n","168/168 - 6s - loss: 0.7978 - accuracy: 0.9713 - val_loss: 1.1018 - val_accuracy: 0.8095 - 6s/epoch - 35ms/step\n","Epoch 5/100\n","168/168 - 6s - loss: 0.5705 - accuracy: 0.9800 - val_loss: 1.5793 - val_accuracy: 0.8274 - 6s/epoch - 34ms/step\n","Epoch 6/100\n","168/168 - 6s - loss: 0.4753 - accuracy: 0.9826 - val_loss: 1.8386 - val_accuracy: 0.6508 - 6s/epoch - 34ms/step\n","Epoch 7/100\n","168/168 - 6s - loss: 0.4132 - accuracy: 0.9847 - val_loss: 1.4990 - val_accuracy: 0.8810 - 6s/epoch - 35ms/step\n","Epoch 8/100\n","168/168 - 6s - loss: 0.2183 - accuracy: 0.9925 - val_loss: 1.8508 - val_accuracy: 0.8849 - 6s/epoch - 35ms/step\n","Epoch 9/100\n","168/168 - 6s - loss: 0.2186 - accuracy: 0.9914 - val_loss: 2.3980 - val_accuracy: 0.7381 - 6s/epoch - 35ms/step\n","Epoch 10/100\n","168/168 - 6s - loss: 0.1759 - accuracy: 0.9948 - val_loss: 2.1793 - val_accuracy: 0.7798 - 6s/epoch - 35ms/step\n","Epoch 11/100\n","168/168 - 6s - loss: 0.3088 - accuracy: 0.9905 - val_loss: 1.9928 - val_accuracy: 0.8849 - 6s/epoch - 35ms/step\n","Epoch 12/100\n","168/168 - 6s - loss: 0.1446 - accuracy: 0.9950 - val_loss: 1.8233 - val_accuracy: 0.8115 - 6s/epoch - 35ms/step\n","Epoch 13/100\n","168/168 - 6s - loss: 0.2141 - accuracy: 0.9929 - val_loss: 1.8705 - val_accuracy: 0.7202 - 6s/epoch - 34ms/step\n","Epoch 14/100\n","168/168 - 6s - loss: 0.2732 - accuracy: 0.9912 - val_loss: 2.0990 - val_accuracy: 0.8829 - 6s/epoch - 34ms/step\n","Epoch 15/100\n","168/168 - 6s - loss: 0.1343 - accuracy: 0.9963 - val_loss: 2.1281 - val_accuracy: 0.7540 - 6s/epoch - 34ms/step\n","Epoch 16/100\n","168/168 - 6s - loss: 0.3471 - accuracy: 0.9871 - val_loss: 3.4167 - val_accuracy: 0.5159 - 6s/epoch - 34ms/step\n","Epoch 16: early stopping\n","42/42 - 1s - 751ms/epoch - 18ms/step\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","Epoch 1/100\n","168/168 - 3s - loss: 4.6178 - accuracy: 0.7800 - val_loss: 0.7487 - val_accuracy: 0.5972 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.2063 - accuracy: 0.9114 - val_loss: 0.4816 - val_accuracy: 0.7857 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.0368 - accuracy: 0.9623 - val_loss: 0.2044 - val_accuracy: 0.9008 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.5397 - accuracy: 0.9825 - val_loss: 1.3524 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.4221 - accuracy: 0.9866 - val_loss: 0.5419 - val_accuracy: 0.8452 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.2780 - accuracy: 0.9920 - val_loss: 0.6942 - val_accuracy: 0.8274 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.2562 - accuracy: 0.9927 - val_loss: 1.2511 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.1802 - accuracy: 0.9946 - val_loss: 0.7784 - val_accuracy: 0.8115 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.1553 - accuracy: 0.9961 - val_loss: 1.5981 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.1334 - accuracy: 0.9961 - val_loss: 1.7190 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.1841 - accuracy: 0.9950 - val_loss: 1.8572 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.1691 - accuracy: 0.9948 - val_loss: 2.0263 - val_accuracy: 0.8016 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1329 - accuracy: 0.9955 - val_loss: 1.7937 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1141 - accuracy: 0.9963 - val_loss: 1.6504 - val_accuracy: 0.8016 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1154 - accuracy: 0.9965 - val_loss: 1.7110 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.2197 - accuracy: 0.9927 - val_loss: 0.8898 - val_accuracy: 0.7996 - 2s/epoch - 14ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.0774 - accuracy: 0.9985 - val_loss: 1.6289 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 18/100\n","168/168 - 2s - loss: 0.0977 - accuracy: 0.9972 - val_loss: 2.2955 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 18: early stopping\n","42/42 - 0s - 224ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.8178 - accuracy: 0.6835 - val_loss: 0.6224 - val_accuracy: 0.5496 - 3s/epoch - 19ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.9234 - accuracy: 0.8884 - val_loss: 3.6597 - val_accuracy: 0.1984 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.4228 - accuracy: 0.9504 - val_loss: 5.6056 - val_accuracy: 0.2183 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.9533 - accuracy: 0.9677 - val_loss: 4.5712 - val_accuracy: 0.3909 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.6794 - accuracy: 0.9772 - val_loss: 2.8530 - val_accuracy: 0.5595 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.5667 - accuracy: 0.9813 - val_loss: 4.2814 - val_accuracy: 0.4742 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.4131 - accuracy: 0.9877 - val_loss: 2.6907 - val_accuracy: 0.5377 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.4606 - accuracy: 0.9830 - val_loss: 3.4924 - val_accuracy: 0.5536 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.4392 - accuracy: 0.9877 - val_loss: 3.1766 - val_accuracy: 0.5595 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.3133 - accuracy: 0.9897 - val_loss: 2.6884 - val_accuracy: 0.5556 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.3079 - accuracy: 0.9901 - val_loss: 2.0708 - val_accuracy: 0.5873 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2430 - accuracy: 0.9920 - val_loss: 2.4468 - val_accuracy: 0.5694 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.2682 - accuracy: 0.9907 - val_loss: 1.3163 - val_accuracy: 0.7976 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.2869 - accuracy: 0.9916 - val_loss: 1.7021 - val_accuracy: 0.6230 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.2250 - accuracy: 0.9935 - val_loss: 0.9658 - val_accuracy: 0.8591 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1832 - accuracy: 0.9937 - val_loss: 1.1824 - val_accuracy: 0.8552 - 2s/epoch - 14ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 193ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.3293 - accuracy: 0.7134 - val_loss: 0.5707 - val_accuracy: 0.8095 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.5479 - accuracy: 0.8985 - val_loss: 0.6986 - val_accuracy: 0.6310 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.3618 - accuracy: 0.9492 - val_loss: 0.9371 - val_accuracy: 0.8651 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.8896 - accuracy: 0.9685 - val_loss: 1.2434 - val_accuracy: 0.6270 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.5429 - accuracy: 0.9847 - val_loss: 5.8783 - val_accuracy: 0.0992 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4314 - accuracy: 0.9881 - val_loss: 1.8828 - val_accuracy: 0.4246 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.2916 - accuracy: 0.9912 - val_loss: 1.9304 - val_accuracy: 0.5060 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.2673 - accuracy: 0.9922 - val_loss: 1.8976 - val_accuracy: 0.5119 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2028 - accuracy: 0.9946 - val_loss: 1.4407 - val_accuracy: 0.8135 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2087 - accuracy: 0.9938 - val_loss: 2.8815 - val_accuracy: 0.2996 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.2219 - accuracy: 0.9927 - val_loss: 1.2469 - val_accuracy: 0.8829 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.1708 - accuracy: 0.9951 - val_loss: 1.5492 - val_accuracy: 0.8829 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1936 - accuracy: 0.9937 - val_loss: 1.6292 - val_accuracy: 0.8373 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1168 - accuracy: 0.9970 - val_loss: 2.0622 - val_accuracy: 0.5754 - 2s/epoch - 15ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.2617 - accuracy: 0.9916 - val_loss: 2.3347 - val_accuracy: 0.4206 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1839 - accuracy: 0.9944 - val_loss: 2.5643 - val_accuracy: 0.4226 - 2s/epoch - 14ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 223ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 4.5287 - accuracy: 0.7850 - val_loss: 0.8739 - val_accuracy: 0.6210 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.7569 - accuracy: 0.9468 - val_loss: 0.7786 - val_accuracy: 0.5496 - 3s/epoch - 18ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 1.1758 - accuracy: 0.9647 - val_loss: 1.9278 - val_accuracy: 0.4365 - 3s/epoch - 17ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.9086 - accuracy: 0.9688 - val_loss: 0.9701 - val_accuracy: 0.5317 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.6110 - accuracy: 0.9804 - val_loss: 0.5615 - val_accuracy: 0.8631 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4784 - accuracy: 0.9840 - val_loss: 0.6155 - val_accuracy: 0.8770 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.4206 - accuracy: 0.9873 - val_loss: 0.5144 - val_accuracy: 0.8790 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.3968 - accuracy: 0.9860 - val_loss: 0.7860 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.3166 - accuracy: 0.9912 - val_loss: 0.5737 - val_accuracy: 0.8214 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2795 - accuracy: 0.9910 - val_loss: 1.2240 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.2484 - accuracy: 0.9933 - val_loss: 0.7793 - val_accuracy: 0.8730 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2088 - accuracy: 0.9940 - val_loss: 0.6670 - val_accuracy: 0.8095 - 2s/epoch - 15ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1879 - accuracy: 0.9942 - val_loss: 0.9936 - val_accuracy: 0.8849 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.2916 - accuracy: 0.9918 - val_loss: 1.2698 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1697 - accuracy: 0.9951 - val_loss: 1.0571 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1333 - accuracy: 0.9963 - val_loss: 1.0586 - val_accuracy: 0.6746 - 2s/epoch - 14ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.1294 - accuracy: 0.9970 - val_loss: 1.2868 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 18/100\n","168/168 - 2s - loss: 0.1850 - accuracy: 0.9946 - val_loss: 1.3489 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 19/100\n","168/168 - 2s - loss: 0.1606 - accuracy: 0.9950 - val_loss: 1.2148 - val_accuracy: 0.7024 - 2s/epoch - 14ms/step\n","Epoch 20/100\n","168/168 - 2s - loss: 0.1515 - accuracy: 0.9948 - val_loss: 1.2690 - val_accuracy: 0.6865 - 2s/epoch - 15ms/step\n","Epoch 21/100\n","168/168 - 2s - loss: 0.1331 - accuracy: 0.9963 - val_loss: 1.3336 - val_accuracy: 0.8810 - 2s/epoch - 14ms/step\n","Epoch 22/100\n","168/168 - 2s - loss: 0.1034 - accuracy: 0.9963 - val_loss: 1.4456 - val_accuracy: 0.8849 - 2s/epoch - 14ms/step\n","Epoch 22: early stopping\n","42/42 - 0s - 222ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.6511 - accuracy: 0.6843 - val_loss: 0.3764 - val_accuracy: 0.8770 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.7382 - accuracy: 0.8882 - val_loss: 0.1840 - val_accuracy: 0.8909 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.5158 - accuracy: 0.9401 - val_loss: 0.9077 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.8419 - accuracy: 0.9696 - val_loss: 0.8000 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.5734 - accuracy: 0.9819 - val_loss: 0.9782 - val_accuracy: 0.8591 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4823 - accuracy: 0.9841 - val_loss: 0.8432 - val_accuracy: 0.8254 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.4086 - accuracy: 0.9873 - val_loss: 1.3618 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.5057 - accuracy: 0.9821 - val_loss: 1.0173 - val_accuracy: 0.5258 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.3181 - accuracy: 0.9896 - val_loss: 2.5913 - val_accuracy: 0.2440 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2765 - accuracy: 0.9920 - val_loss: 1.3258 - val_accuracy: 0.8651 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.2377 - accuracy: 0.9918 - val_loss: 1.4133 - val_accuracy: 0.6250 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2799 - accuracy: 0.9912 - val_loss: 1.3961 - val_accuracy: 0.8948 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.2109 - accuracy: 0.9925 - val_loss: 1.4637 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.3636 - accuracy: 0.9871 - val_loss: 1.3649 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1674 - accuracy: 0.9959 - val_loss: 1.2541 - val_accuracy: 0.8611 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1087 - accuracy: 0.9965 - val_loss: 1.4146 - val_accuracy: 0.8194 - 2s/epoch - 14ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.2005 - accuracy: 0.9925 - val_loss: 1.6692 - val_accuracy: 0.6190 - 2s/epoch - 14ms/step\n","Epoch 17: early stopping\n","42/42 - 0s - 217ms/epoch - 5ms/step\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","Epoch 1/100\n","168/168 - 4s - loss: 3.7923 - accuracy: 0.8192 - val_loss: 0.8909 - val_accuracy: 0.3770 - 4s/epoch - 21ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.0761 - accuracy: 0.9610 - val_loss: 0.4867 - val_accuracy: 0.8631 - 3s/epoch - 15ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 0.4573 - accuracy: 0.9834 - val_loss: 1.2041 - val_accuracy: 0.8075 - 2s/epoch - 15ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.4611 - accuracy: 0.9849 - val_loss: 1.0764 - val_accuracy: 0.5397 - 3s/epoch - 15ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.2034 - accuracy: 0.9938 - val_loss: 0.9246 - val_accuracy: 0.6687 - 3s/epoch - 15ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.1544 - accuracy: 0.9951 - val_loss: 1.4554 - val_accuracy: 0.8036 - 3s/epoch - 15ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.1785 - accuracy: 0.9946 - val_loss: 1.3492 - val_accuracy: 0.8036 - 3s/epoch - 15ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.0735 - accuracy: 0.9983 - val_loss: 1.3192 - val_accuracy: 0.8016 - 3s/epoch - 15ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.1543 - accuracy: 0.9950 - val_loss: 1.9793 - val_accuracy: 0.8036 - 3s/epoch - 15ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.2607 - accuracy: 0.9922 - val_loss: 1.5726 - val_accuracy: 0.8036 - 3s/epoch - 16ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.1905 - accuracy: 0.9948 - val_loss: 2.5491 - val_accuracy: 0.8036 - 3s/epoch - 15ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.1061 - accuracy: 0.9970 - val_loss: 0.9325 - val_accuracy: 0.7976 - 3s/epoch - 15ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.0892 - accuracy: 0.9976 - val_loss: 2.1768 - val_accuracy: 0.8036 - 3s/epoch - 15ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.1034 - accuracy: 0.9970 - val_loss: 0.8946 - val_accuracy: 0.8175 - 3s/epoch - 15ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.0542 - accuracy: 0.9987 - val_loss: 1.9686 - val_accuracy: 0.8036 - 3s/epoch - 16ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.0867 - accuracy: 0.9972 - val_loss: 0.9507 - val_accuracy: 0.8413 - 3s/epoch - 15ms/step\n","Epoch 17/100\n","168/168 - 3s - loss: 0.1421 - accuracy: 0.9957 - val_loss: 1.6528 - val_accuracy: 0.8472 - 3s/epoch - 16ms/step\n","Epoch 17: early stopping\n","42/42 - 0s - 267ms/epoch - 6ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 4.8612 - accuracy: 0.7653 - val_loss: 0.3465 - val_accuracy: 0.8988 - 3s/epoch - 21ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.7113 - accuracy: 0.9354 - val_loss: 0.8870 - val_accuracy: 0.5000 - 3s/epoch - 15ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 0.8887 - accuracy: 0.9711 - val_loss: 2.0587 - val_accuracy: 0.2282 - 3s/epoch - 15ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.5370 - accuracy: 0.9832 - val_loss: 1.0920 - val_accuracy: 0.9008 - 3s/epoch - 15ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.4832 - accuracy: 0.9838 - val_loss: 4.1612 - val_accuracy: 0.2083 - 2s/epoch - 15ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.2396 - accuracy: 0.9937 - val_loss: 0.4860 - val_accuracy: 0.8869 - 2s/epoch - 15ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.2438 - accuracy: 0.9916 - val_loss: 0.3726 - val_accuracy: 0.8869 - 3s/epoch - 15ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.1679 - accuracy: 0.9942 - val_loss: 0.3467 - val_accuracy: 0.8849 - 2s/epoch - 15ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.1061 - accuracy: 0.9976 - val_loss: 1.3103 - val_accuracy: 0.9028 - 3s/epoch - 15ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.1712 - accuracy: 0.9950 - val_loss: 0.8963 - val_accuracy: 0.8909 - 3s/epoch - 15ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.0844 - accuracy: 0.9978 - val_loss: 0.7826 - val_accuracy: 0.7480 - 2s/epoch - 15ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.0767 - accuracy: 0.9983 - val_loss: 1.2796 - val_accuracy: 0.8988 - 2s/epoch - 15ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.1773 - accuracy: 0.9950 - val_loss: 0.7903 - val_accuracy: 0.9028 - 3s/epoch - 15ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.1360 - accuracy: 0.9966 - val_loss: 1.6624 - val_accuracy: 0.3651 - 3s/epoch - 15ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.0668 - accuracy: 0.9989 - val_loss: 0.7276 - val_accuracy: 0.9028 - 3s/epoch - 15ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.0721 - accuracy: 0.9979 - val_loss: 0.7545 - val_accuracy: 0.8988 - 2s/epoch - 15ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 211ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 4.9047 - accuracy: 0.7472 - val_loss: 0.3529 - val_accuracy: 0.8869 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 1.6944 - accuracy: 0.9373 - val_loss: 0.4479 - val_accuracy: 0.8968 - 2s/epoch - 15ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 0.7822 - accuracy: 0.9728 - val_loss: 0.9296 - val_accuracy: 0.9028 - 3s/epoch - 15ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.5111 - accuracy: 0.9813 - val_loss: 1.0666 - val_accuracy: 0.9028 - 3s/epoch - 15ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.3590 - accuracy: 0.9888 - val_loss: 1.1608 - val_accuracy: 0.8968 - 3s/epoch - 15ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.2118 - accuracy: 0.9938 - val_loss: 1.0991 - val_accuracy: 0.8770 - 2s/epoch - 15ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.2550 - accuracy: 0.9918 - val_loss: 1.2301 - val_accuracy: 0.8750 - 2s/epoch - 15ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.1744 - accuracy: 0.9950 - val_loss: 1.3191 - val_accuracy: 0.8829 - 3s/epoch - 15ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.1567 - accuracy: 0.9942 - val_loss: 1.3099 - val_accuracy: 0.8492 - 3s/epoch - 15ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.1562 - accuracy: 0.9951 - val_loss: 1.3939 - val_accuracy: 0.8810 - 2s/epoch - 15ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.0849 - accuracy: 0.9983 - val_loss: 1.5143 - val_accuracy: 0.8849 - 3s/epoch - 15ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.1823 - accuracy: 0.9940 - val_loss: 1.4201 - val_accuracy: 0.8909 - 3s/epoch - 15ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.1880 - accuracy: 0.9944 - val_loss: 1.4322 - val_accuracy: 0.8095 - 3s/epoch - 15ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.0467 - accuracy: 0.9993 - val_loss: 1.3319 - val_accuracy: 0.8671 - 2s/epoch - 15ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.0776 - accuracy: 0.9966 - val_loss: 1.5132 - val_accuracy: 0.8849 - 3s/epoch - 15ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.0744 - accuracy: 0.9978 - val_loss: 1.4709 - val_accuracy: 0.8770 - 3s/epoch - 15ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 201ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 4.0494 - accuracy: 0.8190 - val_loss: 0.2707 - val_accuracy: 0.9028 - 3s/epoch - 21ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 1.2026 - accuracy: 0.9601 - val_loss: 0.3257 - val_accuracy: 0.9028 - 2s/epoch - 15ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 0.6996 - accuracy: 0.9772 - val_loss: 0.6294 - val_accuracy: 0.8869 - 3s/epoch - 15ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.4600 - accuracy: 0.9868 - val_loss: 0.7855 - val_accuracy: 0.7143 - 3s/epoch - 15ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.3792 - accuracy: 0.9875 - val_loss: 1.0889 - val_accuracy: 0.8988 - 3s/epoch - 17ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.3267 - accuracy: 0.9899 - val_loss: 1.3120 - val_accuracy: 0.9008 - 3s/epoch - 18ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.1688 - accuracy: 0.9948 - val_loss: 1.1476 - val_accuracy: 0.8810 - 3s/epoch - 16ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.1651 - accuracy: 0.9944 - val_loss: 1.0467 - val_accuracy: 0.8869 - 3s/epoch - 15ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.2587 - accuracy: 0.9910 - val_loss: 1.0998 - val_accuracy: 0.8849 - 3s/epoch - 15ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.1257 - accuracy: 0.9965 - val_loss: 1.0328 - val_accuracy: 0.8829 - 3s/epoch - 16ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.0912 - accuracy: 0.9974 - val_loss: 1.2773 - val_accuracy: 0.8810 - 3s/epoch - 16ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.1058 - accuracy: 0.9974 - val_loss: 1.5727 - val_accuracy: 0.9028 - 3s/epoch - 15ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.2075 - accuracy: 0.9933 - val_loss: 1.4113 - val_accuracy: 0.9028 - 3s/epoch - 15ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.1312 - accuracy: 0.9961 - val_loss: 1.4961 - val_accuracy: 0.8869 - 3s/epoch - 15ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.0951 - accuracy: 0.9978 - val_loss: 1.1548 - val_accuracy: 0.8849 - 3s/epoch - 16ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.0959 - accuracy: 0.9972 - val_loss: 1.6362 - val_accuracy: 0.8909 - 3s/epoch - 15ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 247ms/epoch - 6ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 4.6407 - accuracy: 0.7619 - val_loss: 0.3792 - val_accuracy: 0.9028 - 3s/epoch - 21ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 1.2023 - accuracy: 0.9565 - val_loss: 0.9274 - val_accuracy: 0.9008 - 2s/epoch - 15ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 0.6027 - accuracy: 0.9821 - val_loss: 1.2121 - val_accuracy: 0.8869 - 2s/epoch - 15ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.4568 - accuracy: 0.9862 - val_loss: 1.3706 - val_accuracy: 0.5873 - 2s/epoch - 15ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.3016 - accuracy: 0.9899 - val_loss: 1.1924 - val_accuracy: 0.8234 - 2s/epoch - 15ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.2741 - accuracy: 0.9929 - val_loss: 1.4040 - val_accuracy: 0.8790 - 2s/epoch - 15ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.1613 - accuracy: 0.9951 - val_loss: 1.6269 - val_accuracy: 0.8849 - 2s/epoch - 15ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.1067 - accuracy: 0.9974 - val_loss: 1.8071 - val_accuracy: 0.8849 - 2s/epoch - 15ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2014 - accuracy: 0.9940 - val_loss: 1.6415 - val_accuracy: 0.8770 - 2s/epoch - 15ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.2474 - accuracy: 0.9924 - val_loss: 1.8003 - val_accuracy: 0.8968 - 3s/epoch - 15ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.0640 - accuracy: 0.9983 - val_loss: 1.7403 - val_accuracy: 0.8869 - 3s/epoch - 15ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.0685 - accuracy: 0.9979 - val_loss: 1.4693 - val_accuracy: 0.8829 - 2s/epoch - 15ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.2358 - accuracy: 0.9931 - val_loss: 1.8512 - val_accuracy: 0.8869 - 2s/epoch - 15ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.0988 - accuracy: 0.9970 - val_loss: 1.5056 - val_accuracy: 0.8829 - 2s/epoch - 15ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.0872 - accuracy: 0.9968 - val_loss: 1.6182 - val_accuracy: 0.8869 - 3s/epoch - 15ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.0518 - accuracy: 0.9989 - val_loss: 1.8604 - val_accuracy: 0.8869 - 3s/epoch - 15ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 226ms/epoch - 5ms/step\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","Epoch 1/100\n","168/168 - 6s - loss: 4.7914 - accuracy: 0.7755 - val_loss: 0.4647 - val_accuracy: 0.8869 - 6s/epoch - 34ms/step\n","Epoch 2/100\n","168/168 - 4s - loss: 2.3557 - accuracy: 0.9065 - val_loss: 0.4055 - val_accuracy: 0.8948 - 4s/epoch - 24ms/step\n","Epoch 3/100\n","168/168 - 4s - loss: 1.2832 - accuracy: 0.9500 - val_loss: 0.9744 - val_accuracy: 0.8810 - 4s/epoch - 24ms/step\n","Epoch 4/100\n","168/168 - 4s - loss: 0.8308 - accuracy: 0.9694 - val_loss: 1.5963 - val_accuracy: 0.9028 - 4s/epoch - 24ms/step\n","Epoch 5/100\n","168/168 - 4s - loss: 0.7048 - accuracy: 0.9746 - val_loss: 1.0097 - val_accuracy: 0.8869 - 4s/epoch - 24ms/step\n","Epoch 6/100\n","168/168 - 4s - loss: 0.4827 - accuracy: 0.9813 - val_loss: 1.6940 - val_accuracy: 0.8929 - 4s/epoch - 24ms/step\n","Epoch 7/100\n","168/168 - 4s - loss: 0.3904 - accuracy: 0.9873 - val_loss: 1.3304 - val_accuracy: 0.8829 - 4s/epoch - 24ms/step\n","Epoch 8/100\n","168/168 - 4s - loss: 0.3914 - accuracy: 0.9868 - val_loss: 1.2508 - val_accuracy: 0.8829 - 4s/epoch - 24ms/step\n","Epoch 9/100\n","168/168 - 4s - loss: 0.2740 - accuracy: 0.9896 - val_loss: 1.2894 - val_accuracy: 0.8790 - 4s/epoch - 24ms/step\n","Epoch 10/100\n","168/168 - 4s - loss: 0.2818 - accuracy: 0.9901 - val_loss: 0.9913 - val_accuracy: 0.8075 - 4s/epoch - 24ms/step\n","Epoch 11/100\n","168/168 - 4s - loss: 0.2172 - accuracy: 0.9935 - val_loss: 1.9720 - val_accuracy: 0.8135 - 4s/epoch - 24ms/step\n","Epoch 12/100\n","168/168 - 4s - loss: 0.1729 - accuracy: 0.9933 - val_loss: 0.8068 - val_accuracy: 0.7579 - 4s/epoch - 24ms/step\n","Epoch 13/100\n","168/168 - 4s - loss: 0.2611 - accuracy: 0.9909 - val_loss: 1.2224 - val_accuracy: 0.8849 - 4s/epoch - 24ms/step\n","Epoch 14/100\n","168/168 - 4s - loss: 0.2095 - accuracy: 0.9938 - val_loss: 1.5428 - val_accuracy: 0.8869 - 4s/epoch - 24ms/step\n","Epoch 15/100\n","168/168 - 4s - loss: 0.2586 - accuracy: 0.9922 - val_loss: 1.0530 - val_accuracy: 0.8869 - 4s/epoch - 24ms/step\n","Epoch 16/100\n","168/168 - 4s - loss: 0.1369 - accuracy: 0.9959 - val_loss: 1.4320 - val_accuracy: 0.8869 - 4s/epoch - 24ms/step\n","Epoch 17/100\n","168/168 - 4s - loss: 0.2055 - accuracy: 0.9920 - val_loss: 0.9821 - val_accuracy: 0.8750 - 4s/epoch - 24ms/step\n","Epoch 17: early stopping\n","42/42 - 1s - 729ms/epoch - 17ms/step\n","Epoch 1/100\n","168/168 - 5s - loss: 5.6472 - accuracy: 0.7130 - val_loss: 0.3795 - val_accuracy: 0.9226 - 5s/epoch - 29ms/step\n","Epoch 2/100\n","168/168 - 4s - loss: 2.6337 - accuracy: 0.8949 - val_loss: 0.5714 - val_accuracy: 0.8948 - 4s/epoch - 24ms/step\n","Epoch 3/100\n","168/168 - 4s - loss: 1.1601 - accuracy: 0.9623 - val_loss: 0.6760 - val_accuracy: 0.8810 - 4s/epoch - 24ms/step\n","Epoch 4/100\n","168/168 - 4s - loss: 0.6841 - accuracy: 0.9769 - val_loss: 0.4385 - val_accuracy: 0.8532 - 4s/epoch - 24ms/step\n","Epoch 5/100\n","168/168 - 4s - loss: 0.5017 - accuracy: 0.9826 - val_loss: 0.6135 - val_accuracy: 0.8194 - 4s/epoch - 24ms/step\n","Epoch 6/100\n","168/168 - 4s - loss: 0.3954 - accuracy: 0.9869 - val_loss: 0.9642 - val_accuracy: 0.7321 - 4s/epoch - 24ms/step\n","Epoch 7/100\n","168/168 - 4s - loss: 0.3887 - accuracy: 0.9869 - val_loss: 7.3472 - val_accuracy: 0.2341 - 4s/epoch - 24ms/step\n","Epoch 8/100\n","168/168 - 4s - loss: 0.3581 - accuracy: 0.9866 - val_loss: 0.8588 - val_accuracy: 0.7560 - 4s/epoch - 24ms/step\n","Epoch 9/100\n","168/168 - 4s - loss: 0.4598 - accuracy: 0.9862 - val_loss: 1.3561 - val_accuracy: 0.8849 - 4s/epoch - 24ms/step\n","Epoch 10/100\n","168/168 - 4s - loss: 0.2416 - accuracy: 0.9923 - val_loss: 0.9337 - val_accuracy: 0.7460 - 4s/epoch - 24ms/step\n","Epoch 11/100\n","168/168 - 4s - loss: 0.1923 - accuracy: 0.9946 - val_loss: 1.9031 - val_accuracy: 0.5873 - 4s/epoch - 24ms/step\n","Epoch 12/100\n","168/168 - 4s - loss: 0.2910 - accuracy: 0.9914 - val_loss: 4.2747 - val_accuracy: 0.3671 - 4s/epoch - 24ms/step\n","Epoch 13/100\n","168/168 - 4s - loss: 0.1556 - accuracy: 0.9955 - val_loss: 0.8634 - val_accuracy: 0.8750 - 4s/epoch - 24ms/step\n","Epoch 14/100\n","168/168 - 4s - loss: 0.1723 - accuracy: 0.9950 - val_loss: 1.3706 - val_accuracy: 0.8810 - 4s/epoch - 24ms/step\n","Epoch 15/100\n","168/168 - 4s - loss: 0.2852 - accuracy: 0.9894 - val_loss: 1.2714 - val_accuracy: 0.8750 - 4s/epoch - 24ms/step\n","Epoch 16/100\n","168/168 - 4s - loss: 0.1798 - accuracy: 0.9933 - val_loss: 1.1926 - val_accuracy: 0.7560 - 4s/epoch - 24ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 488ms/epoch - 12ms/step\n","Epoch 1/100\n","168/168 - 5s - loss: 5.5084 - accuracy: 0.7096 - val_loss: 0.3942 - val_accuracy: 0.8869 - 5s/epoch - 29ms/step\n","Epoch 2/100\n","168/168 - 4s - loss: 2.2857 - accuracy: 0.9162 - val_loss: 1.2896 - val_accuracy: 0.3274 - 4s/epoch - 24ms/step\n","Epoch 3/100\n","168/168 - 4s - loss: 1.2506 - accuracy: 0.9520 - val_loss: 1.0092 - val_accuracy: 0.7798 - 4s/epoch - 24ms/step\n","Epoch 4/100\n","168/168 - 4s - loss: 0.7903 - accuracy: 0.9718 - val_loss: 1.3051 - val_accuracy: 0.7024 - 4s/epoch - 24ms/step\n","Epoch 5/100\n","168/168 - 4s - loss: 0.5927 - accuracy: 0.9785 - val_loss: 1.2692 - val_accuracy: 0.8175 - 4s/epoch - 24ms/step\n","Epoch 6/100\n","168/168 - 4s - loss: 0.4425 - accuracy: 0.9847 - val_loss: 1.9359 - val_accuracy: 0.5714 - 4s/epoch - 24ms/step\n","Epoch 7/100\n","168/168 - 4s - loss: 0.4308 - accuracy: 0.9860 - val_loss: 1.2322 - val_accuracy: 0.8413 - 4s/epoch - 24ms/step\n","Epoch 8/100\n","168/168 - 4s - loss: 0.3254 - accuracy: 0.9890 - val_loss: 1.2725 - val_accuracy: 0.7242 - 4s/epoch - 24ms/step\n","Epoch 9/100\n","168/168 - 4s - loss: 0.2156 - accuracy: 0.9910 - val_loss: 1.3134 - val_accuracy: 0.8651 - 4s/epoch - 24ms/step\n","Epoch 10/100\n","168/168 - 4s - loss: 0.2197 - accuracy: 0.9931 - val_loss: 2.0041 - val_accuracy: 0.8790 - 4s/epoch - 25ms/step\n","Epoch 11/100\n","168/168 - 4s - loss: 0.1638 - accuracy: 0.9948 - val_loss: 2.8223 - val_accuracy: 0.5496 - 4s/epoch - 25ms/step\n","Epoch 12/100\n","168/168 - 4s - loss: 0.2454 - accuracy: 0.9922 - val_loss: 1.2962 - val_accuracy: 0.8373 - 4s/epoch - 24ms/step\n","Epoch 13/100\n","168/168 - 4s - loss: 0.3538 - accuracy: 0.9868 - val_loss: 2.2699 - val_accuracy: 0.5595 - 4s/epoch - 24ms/step\n","Epoch 14/100\n","168/168 - 4s - loss: 0.1827 - accuracy: 0.9935 - val_loss: 1.7966 - val_accuracy: 0.8849 - 4s/epoch - 24ms/step\n","Epoch 15/100\n","168/168 - 4s - loss: 0.1875 - accuracy: 0.9925 - val_loss: 1.4529 - val_accuracy: 0.7440 - 4s/epoch - 24ms/step\n","Epoch 16/100\n","168/168 - 4s - loss: 0.1053 - accuracy: 0.9961 - val_loss: 1.6363 - val_accuracy: 0.7599 - 4s/epoch - 24ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 471ms/epoch - 11ms/step\n","Epoch 1/100\n","168/168 - 5s - loss: 4.6492 - accuracy: 0.7807 - val_loss: 0.3720 - val_accuracy: 0.8968 - 5s/epoch - 29ms/step\n","Epoch 2/100\n","168/168 - 4s - loss: 2.0174 - accuracy: 0.9304 - val_loss: 0.3083 - val_accuracy: 0.9008 - 4s/epoch - 24ms/step\n","Epoch 3/100\n","168/168 - 4s - loss: 1.1169 - accuracy: 0.9627 - val_loss: 0.6107 - val_accuracy: 0.7520 - 4s/epoch - 24ms/step\n","Epoch 4/100\n","168/168 - 4s - loss: 0.7961 - accuracy: 0.9716 - val_loss: 0.5735 - val_accuracy: 0.8869 - 4s/epoch - 24ms/step\n","Epoch 5/100\n","168/168 - 4s - loss: 0.6356 - accuracy: 0.9750 - val_loss: 0.9508 - val_accuracy: 0.9028 - 4s/epoch - 24ms/step\n","Epoch 6/100\n","168/168 - 4s - loss: 0.5630 - accuracy: 0.9802 - val_loss: 1.4133 - val_accuracy: 0.5794 - 4s/epoch - 24ms/step\n","Epoch 7/100\n","168/168 - 4s - loss: 0.3536 - accuracy: 0.9896 - val_loss: 1.1026 - val_accuracy: 0.8790 - 4s/epoch - 24ms/step\n","Epoch 8/100\n","168/168 - 4s - loss: 0.2994 - accuracy: 0.9892 - val_loss: 1.0463 - val_accuracy: 0.8750 - 4s/epoch - 24ms/step\n","Epoch 9/100\n","168/168 - 4s - loss: 0.2736 - accuracy: 0.9892 - val_loss: 1.2756 - val_accuracy: 0.7063 - 4s/epoch - 24ms/step\n","Epoch 10/100\n","168/168 - 4s - loss: 0.1948 - accuracy: 0.9916 - val_loss: 1.6220 - val_accuracy: 0.9028 - 4s/epoch - 24ms/step\n","Epoch 11/100\n","168/168 - 4s - loss: 0.2163 - accuracy: 0.9933 - val_loss: 1.2740 - val_accuracy: 0.6766 - 4s/epoch - 24ms/step\n","Epoch 12/100\n","168/168 - 4s - loss: 0.2857 - accuracy: 0.9910 - val_loss: 1.1051 - val_accuracy: 0.8790 - 4s/epoch - 24ms/step\n","Epoch 13/100\n","168/168 - 4s - loss: 0.1514 - accuracy: 0.9951 - val_loss: 1.0899 - val_accuracy: 0.8036 - 4s/epoch - 24ms/step\n","Epoch 14/100\n","168/168 - 4s - loss: 0.2192 - accuracy: 0.9933 - val_loss: 1.5896 - val_accuracy: 0.5476 - 4s/epoch - 24ms/step\n","Epoch 15/100\n","168/168 - 4s - loss: 0.2055 - accuracy: 0.9938 - val_loss: 2.8898 - val_accuracy: 0.2500 - 4s/epoch - 24ms/step\n","Epoch 16/100\n","168/168 - 4s - loss: 0.3530 - accuracy: 0.9907 - val_loss: 1.9904 - val_accuracy: 0.9028 - 4s/epoch - 24ms/step\n","Epoch 17/100\n","168/168 - 4s - loss: 0.2489 - accuracy: 0.9923 - val_loss: 1.1941 - val_accuracy: 0.7599 - 4s/epoch - 24ms/step\n","Epoch 17: early stopping\n","42/42 - 0s - 373ms/epoch - 9ms/step\n","Epoch 1/100\n","168/168 - 5s - loss: 6.2330 - accuracy: 0.6606 - val_loss: 0.3223 - val_accuracy: 0.8948 - 5s/epoch - 31ms/step\n","Epoch 2/100\n","168/168 - 4s - loss: 2.7551 - accuracy: 0.8840 - val_loss: 0.5130 - val_accuracy: 0.8254 - 4s/epoch - 24ms/step\n","Epoch 3/100\n","168/168 - 4s - loss: 1.2761 - accuracy: 0.9537 - val_loss: 1.1630 - val_accuracy: 0.8790 - 4s/epoch - 24ms/step\n","Epoch 4/100\n","168/168 - 4s - loss: 0.7276 - accuracy: 0.9741 - val_loss: 1.5556 - val_accuracy: 0.7599 - 4s/epoch - 24ms/step\n","Epoch 5/100\n","168/168 - 4s - loss: 0.5015 - accuracy: 0.9812 - val_loss: 1.9296 - val_accuracy: 0.8353 - 4s/epoch - 24ms/step\n","Epoch 6/100\n","168/168 - 4s - loss: 0.3628 - accuracy: 0.9849 - val_loss: 3.3306 - val_accuracy: 0.4484 - 4s/epoch - 24ms/step\n","Epoch 7/100\n","168/168 - 4s - loss: 0.3969 - accuracy: 0.9853 - val_loss: 2.0853 - val_accuracy: 0.8373 - 4s/epoch - 24ms/step\n","Epoch 8/100\n","168/168 - 4s - loss: 0.1750 - accuracy: 0.9953 - val_loss: 4.3983 - val_accuracy: 0.4444 - 4s/epoch - 24ms/step\n","Epoch 9/100\n","168/168 - 4s - loss: 0.1588 - accuracy: 0.9942 - val_loss: 2.5820 - val_accuracy: 0.8968 - 4s/epoch - 24ms/step\n","Epoch 10/100\n","168/168 - 4s - loss: 0.4387 - accuracy: 0.9873 - val_loss: 2.7187 - val_accuracy: 0.9028 - 4s/epoch - 24ms/step\n","Epoch 11/100\n","168/168 - 4s - loss: 0.2589 - accuracy: 0.9922 - val_loss: 2.4539 - val_accuracy: 0.8889 - 4s/epoch - 24ms/step\n","Epoch 12/100\n","168/168 - 4s - loss: 0.1992 - accuracy: 0.9933 - val_loss: 2.0224 - val_accuracy: 0.8254 - 4s/epoch - 24ms/step\n","Epoch 13/100\n","168/168 - 4s - loss: 0.1564 - accuracy: 0.9942 - val_loss: 3.3075 - val_accuracy: 0.5060 - 4s/epoch - 24ms/step\n","Epoch 14/100\n","168/168 - 4s - loss: 0.2139 - accuracy: 0.9940 - val_loss: 4.7453 - val_accuracy: 0.4306 - 4s/epoch - 24ms/step\n","Epoch 15/100\n","168/168 - 4s - loss: 0.1744 - accuracy: 0.9948 - val_loss: 2.7239 - val_accuracy: 0.8869 - 4s/epoch - 24ms/step\n","Epoch 16/100\n","168/168 - 4s - loss: 0.1308 - accuracy: 0.9953 - val_loss: 2.6768 - val_accuracy: 0.8849 - 4s/epoch - 24ms/step\n","Epoch 16: early stopping\n","42/42 - 1s - 719ms/epoch - 17ms/step\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","Epoch 1/100\n","168/168 - 3s - loss: 5.2715 - accuracy: 0.7255 - val_loss: 0.7311 - val_accuracy: 0.6052 - 3s/epoch - 19ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.6705 - accuracy: 0.8979 - val_loss: 0.3317 - val_accuracy: 0.8810 - 2s/epoch - 12ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.3326 - accuracy: 0.9491 - val_loss: 1.0835 - val_accuracy: 0.5794 - 2s/epoch - 13ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.7270 - accuracy: 0.9742 - val_loss: 2.5800 - val_accuracy: 0.5417 - 2s/epoch - 12ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.5435 - accuracy: 0.9806 - val_loss: 3.2019 - val_accuracy: 0.5476 - 2s/epoch - 13ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.3977 - accuracy: 0.9864 - val_loss: 2.1702 - val_accuracy: 0.5060 - 2s/epoch - 12ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.3388 - accuracy: 0.9881 - val_loss: 2.1724 - val_accuracy: 0.5179 - 2s/epoch - 12ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.2914 - accuracy: 0.9897 - val_loss: 2.0372 - val_accuracy: 0.8313 - 2s/epoch - 13ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2454 - accuracy: 0.9920 - val_loss: 4.1521 - val_accuracy: 0.5595 - 2s/epoch - 12ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.1968 - accuracy: 0.9933 - val_loss: 1.5562 - val_accuracy: 0.8056 - 2s/epoch - 12ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.1932 - accuracy: 0.9923 - val_loss: 4.1032 - val_accuracy: 0.5119 - 2s/epoch - 12ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.3274 - accuracy: 0.9907 - val_loss: 2.1150 - val_accuracy: 0.5833 - 2s/epoch - 13ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1703 - accuracy: 0.9935 - val_loss: 3.3203 - val_accuracy: 0.5496 - 2s/epoch - 12ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1181 - accuracy: 0.9959 - val_loss: 3.5024 - val_accuracy: 0.5476 - 2s/epoch - 12ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1967 - accuracy: 0.9933 - val_loss: 3.1178 - val_accuracy: 0.4841 - 2s/epoch - 12ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1287 - accuracy: 0.9968 - val_loss: 4.5035 - val_accuracy: 0.5615 - 2s/epoch - 12ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.0871 - accuracy: 0.9968 - val_loss: 2.4667 - val_accuracy: 0.6627 - 2s/epoch - 12ms/step\n","Epoch 17: early stopping\n","42/42 - 0s - 203ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 6.2495 - accuracy: 0.6251 - val_loss: 0.3463 - val_accuracy: 0.8889 - 3s/epoch - 18ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 3.3203 - accuracy: 0.8656 - val_loss: 0.3353 - val_accuracy: 0.8750 - 2s/epoch - 13ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.8001 - accuracy: 0.9310 - val_loss: 0.7197 - val_accuracy: 0.8889 - 2s/epoch - 12ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 1.1972 - accuracy: 0.9565 - val_loss: 0.7873 - val_accuracy: 0.8829 - 2s/epoch - 13ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.8812 - accuracy: 0.9700 - val_loss: 1.0823 - val_accuracy: 0.8869 - 2s/epoch - 13ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.7778 - accuracy: 0.9748 - val_loss: 0.9966 - val_accuracy: 0.8849 - 2s/epoch - 13ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.5087 - accuracy: 0.9808 - val_loss: 1.5123 - val_accuracy: 0.9028 - 2s/epoch - 12ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.4099 - accuracy: 0.9866 - val_loss: 1.2413 - val_accuracy: 0.6587 - 2s/epoch - 12ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.4119 - accuracy: 0.9875 - val_loss: 1.4764 - val_accuracy: 0.8909 - 2s/epoch - 13ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2959 - accuracy: 0.9907 - val_loss: 0.5968 - val_accuracy: 0.7976 - 2s/epoch - 13ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.2485 - accuracy: 0.9916 - val_loss: 0.8120 - val_accuracy: 0.8849 - 2s/epoch - 13ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.3957 - accuracy: 0.9879 - val_loss: 0.9623 - val_accuracy: 0.8849 - 2s/epoch - 12ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1436 - accuracy: 0.9953 - val_loss: 1.2227 - val_accuracy: 0.8869 - 2s/epoch - 13ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1825 - accuracy: 0.9935 - val_loss: 1.5696 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1444 - accuracy: 0.9948 - val_loss: 1.4619 - val_accuracy: 0.9008 - 2s/epoch - 12ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1696 - accuracy: 0.9959 - val_loss: 0.6256 - val_accuracy: 0.8611 - 2s/epoch - 12ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.2231 - accuracy: 0.9922 - val_loss: 1.0933 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 17: early stopping\n","42/42 - 0s - 190ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.7022 - accuracy: 0.6893 - val_loss: 0.3674 - val_accuracy: 0.9067 - 3s/epoch - 18ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 3.1485 - accuracy: 0.8673 - val_loss: 0.2778 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 2.0174 - accuracy: 0.9166 - val_loss: 0.5295 - val_accuracy: 0.7242 - 2s/epoch - 12ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 1.3799 - accuracy: 0.9450 - val_loss: 0.5561 - val_accuracy: 0.8651 - 2s/epoch - 12ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.6899 - accuracy: 0.9752 - val_loss: 0.7753 - val_accuracy: 0.8948 - 2s/epoch - 13ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4539 - accuracy: 0.9853 - val_loss: 1.0053 - val_accuracy: 0.8869 - 2s/epoch - 12ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.5350 - accuracy: 0.9802 - val_loss: 0.9896 - val_accuracy: 0.6627 - 2s/epoch - 12ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.2963 - accuracy: 0.9888 - val_loss: 0.9134 - val_accuracy: 0.8869 - 2s/epoch - 12ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2746 - accuracy: 0.9910 - val_loss: 1.3558 - val_accuracy: 0.8869 - 2s/epoch - 13ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2681 - accuracy: 0.9910 - val_loss: 1.3857 - val_accuracy: 0.7758 - 2s/epoch - 13ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.2778 - accuracy: 0.9910 - val_loss: 1.6031 - val_accuracy: 0.9008 - 2s/epoch - 12ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2688 - accuracy: 0.9912 - val_loss: 1.3635 - val_accuracy: 0.8869 - 2s/epoch - 12ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1882 - accuracy: 0.9927 - val_loss: 2.6539 - val_accuracy: 0.2183 - 2s/epoch - 12ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.2146 - accuracy: 0.9914 - val_loss: 1.3528 - val_accuracy: 0.8294 - 2s/epoch - 12ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1929 - accuracy: 0.9927 - val_loss: 1.8238 - val_accuracy: 0.6210 - 2s/epoch - 13ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1829 - accuracy: 0.9922 - val_loss: 2.2556 - val_accuracy: 0.5893 - 2s/epoch - 12ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.2691 - accuracy: 0.9903 - val_loss: 1.8047 - val_accuracy: 0.9028 - 2s/epoch - 12ms/step\n","Epoch 17: early stopping\n","42/42 - 0s - 180ms/epoch - 4ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.3714 - accuracy: 0.7235 - val_loss: 0.2634 - val_accuracy: 0.9841 - 3s/epoch - 18ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.4533 - accuracy: 0.9084 - val_loss: 0.1663 - val_accuracy: 0.9028 - 2s/epoch - 12ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.6229 - accuracy: 0.9425 - val_loss: 0.3178 - val_accuracy: 0.9187 - 2s/epoch - 12ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 1.2390 - accuracy: 0.9571 - val_loss: 0.1346 - val_accuracy: 0.9167 - 2s/epoch - 13ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.9946 - accuracy: 0.9638 - val_loss: 0.8125 - val_accuracy: 0.5992 - 2s/epoch - 12ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.8537 - accuracy: 0.9687 - val_loss: 0.3465 - val_accuracy: 0.9187 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.5431 - accuracy: 0.9797 - val_loss: 0.7449 - val_accuracy: 0.6528 - 3s/epoch - 17ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.4691 - accuracy: 0.9843 - val_loss: 0.5636 - val_accuracy: 0.8849 - 2s/epoch - 13ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.3695 - accuracy: 0.9871 - val_loss: 0.7526 - val_accuracy: 0.8869 - 2s/epoch - 12ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.3022 - accuracy: 0.9905 - val_loss: 1.1067 - val_accuracy: 0.8869 - 2s/epoch - 12ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.3082 - accuracy: 0.9886 - val_loss: 0.8791 - val_accuracy: 0.9008 - 2s/epoch - 13ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2313 - accuracy: 0.9933 - val_loss: 1.3119 - val_accuracy: 0.8929 - 2s/epoch - 12ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.2392 - accuracy: 0.9909 - val_loss: 1.1280 - val_accuracy: 0.8869 - 2s/epoch - 12ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.2316 - accuracy: 0.9925 - val_loss: 2.0265 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1846 - accuracy: 0.9935 - val_loss: 1.4930 - val_accuracy: 0.8869 - 2s/epoch - 13ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1967 - accuracy: 0.9937 - val_loss: 2.4217 - val_accuracy: 0.4286 - 2s/epoch - 12ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.0888 - accuracy: 0.9976 - val_loss: 1.5652 - val_accuracy: 0.8869 - 2s/epoch - 12ms/step\n","Epoch 18/100\n","168/168 - 2s - loss: 0.1614 - accuracy: 0.9946 - val_loss: 1.7588 - val_accuracy: 0.8849 - 2s/epoch - 12ms/step\n","Epoch 19/100\n","168/168 - 2s - loss: 0.1408 - accuracy: 0.9950 - val_loss: 1.4494 - val_accuracy: 0.6845 - 2s/epoch - 13ms/step\n","Epoch 19: early stopping\n","42/42 - 0s - 210ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 6.7474 - accuracy: 0.5715 - val_loss: 0.6661 - val_accuracy: 0.6230 - 3s/epoch - 18ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 3.3402 - accuracy: 0.8532 - val_loss: 0.3606 - val_accuracy: 0.7540 - 2s/epoch - 12ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.4566 - accuracy: 0.9446 - val_loss: 0.8561 - val_accuracy: 0.6825 - 2s/epoch - 12ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.8974 - accuracy: 0.9688 - val_loss: 1.0436 - val_accuracy: 0.7857 - 2s/epoch - 12ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.5124 - accuracy: 0.9826 - val_loss: 1.4434 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4226 - accuracy: 0.9862 - val_loss: 1.6400 - val_accuracy: 0.7242 - 2s/epoch - 13ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.3863 - accuracy: 0.9882 - val_loss: 1.5819 - val_accuracy: 0.8849 - 2s/epoch - 13ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.2621 - accuracy: 0.9916 - val_loss: 2.0434 - val_accuracy: 0.6944 - 2s/epoch - 13ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2866 - accuracy: 0.9897 - val_loss: 1.9104 - val_accuracy: 0.9028 - 2s/epoch - 12ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.1512 - accuracy: 0.9961 - val_loss: 2.0244 - val_accuracy: 0.8869 - 2s/epoch - 13ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.3560 - accuracy: 0.9910 - val_loss: 1.9289 - val_accuracy: 0.8869 - 2s/epoch - 12ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2018 - accuracy: 0.9920 - val_loss: 2.0444 - val_accuracy: 0.8849 - 2s/epoch - 12ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1056 - accuracy: 0.9963 - val_loss: 2.3866 - val_accuracy: 0.8988 - 2s/epoch - 12ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1748 - accuracy: 0.9933 - val_loss: 2.4351 - val_accuracy: 0.9028 - 2s/epoch - 12ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1706 - accuracy: 0.9937 - val_loss: 2.3300 - val_accuracy: 0.8869 - 2s/epoch - 13ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1389 - accuracy: 0.9957 - val_loss: 2.4388 - val_accuracy: 0.9008 - 2s/epoch - 12ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.0839 - accuracy: 0.9976 - val_loss: 2.2150 - val_accuracy: 0.8750 - 2s/epoch - 12ms/step\n","Epoch 17: early stopping\n","42/42 - 0s - 238ms/epoch - 6ms/step\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","Epoch 1/100\n","168/168 - 3s - loss: 4.8823 - accuracy: 0.7429 - val_loss: 0.4126 - val_accuracy: 0.8710 - 3s/epoch - 19ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 1.5193 - accuracy: 0.9436 - val_loss: 1.0074 - val_accuracy: 0.5813 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 0.7303 - accuracy: 0.9726 - val_loss: 0.4784 - val_accuracy: 0.8909 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.5824 - accuracy: 0.9784 - val_loss: 0.7013 - val_accuracy: 0.8948 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.4639 - accuracy: 0.9860 - val_loss: 0.5468 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4112 - accuracy: 0.9858 - val_loss: 0.4386 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.3124 - accuracy: 0.9892 - val_loss: 0.4892 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.2373 - accuracy: 0.9914 - val_loss: 0.6111 - val_accuracy: 0.8988 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.1960 - accuracy: 0.9935 - val_loss: 0.4440 - val_accuracy: 0.8770 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.1990 - accuracy: 0.9927 - val_loss: 0.5804 - val_accuracy: 0.8929 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.1949 - accuracy: 0.9929 - val_loss: 0.7005 - val_accuracy: 0.8988 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.1472 - accuracy: 0.9950 - val_loss: 0.7179 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1570 - accuracy: 0.9961 - val_loss: 0.8487 - val_accuracy: 0.8631 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1370 - accuracy: 0.9957 - val_loss: 0.7916 - val_accuracy: 0.8968 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1711 - accuracy: 0.9944 - val_loss: 0.6557 - val_accuracy: 0.8909 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1373 - accuracy: 0.9955 - val_loss: 0.9058 - val_accuracy: 0.8968 - 2s/epoch - 14ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 221ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.6338 - accuracy: 0.7033 - val_loss: 0.6030 - val_accuracy: 0.5734 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 3.3589 - accuracy: 0.8584 - val_loss: 0.2372 - val_accuracy: 0.8790 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.9115 - accuracy: 0.9214 - val_loss: 0.2853 - val_accuracy: 0.8770 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 1.0263 - accuracy: 0.9647 - val_loss: 0.3143 - val_accuracy: 0.8710 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.8302 - accuracy: 0.9688 - val_loss: 0.3279 - val_accuracy: 0.8710 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.5584 - accuracy: 0.9808 - val_loss: 0.4886 - val_accuracy: 0.8492 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.5399 - accuracy: 0.9845 - val_loss: 0.9578 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.2646 - accuracy: 0.9918 - val_loss: 0.2795 - val_accuracy: 0.8829 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.3367 - accuracy: 0.9897 - val_loss: 0.2504 - val_accuracy: 0.8889 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2562 - accuracy: 0.9929 - val_loss: 0.3247 - val_accuracy: 0.8750 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.2766 - accuracy: 0.9910 - val_loss: 0.2789 - val_accuracy: 0.9008 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2986 - accuracy: 0.9897 - val_loss: 0.7281 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1732 - accuracy: 0.9950 - val_loss: 0.4992 - val_accuracy: 0.8929 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.2108 - accuracy: 0.9935 - val_loss: 0.3981 - val_accuracy: 0.8849 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1787 - accuracy: 0.9940 - val_loss: 0.5747 - val_accuracy: 0.8929 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1102 - accuracy: 0.9968 - val_loss: 0.6850 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.1073 - accuracy: 0.9965 - val_loss: 0.2264 - val_accuracy: 0.9187 - 2s/epoch - 14ms/step\n","Epoch 18/100\n","168/168 - 2s - loss: 0.2131 - accuracy: 0.9925 - val_loss: 0.3481 - val_accuracy: 0.8790 - 2s/epoch - 14ms/step\n","Epoch 19/100\n","168/168 - 2s - loss: 0.1096 - accuracy: 0.9974 - val_loss: 0.6027 - val_accuracy: 0.8988 - 2s/epoch - 14ms/step\n","Epoch 20/100\n","168/168 - 2s - loss: 0.1712 - accuracy: 0.9938 - val_loss: 1.3689 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 21/100\n","168/168 - 2s - loss: 0.1876 - accuracy: 0.9942 - val_loss: 0.2718 - val_accuracy: 0.8948 - 2s/epoch - 14ms/step\n","Epoch 22/100\n","168/168 - 2s - loss: 0.1027 - accuracy: 0.9965 - val_loss: 0.2558 - val_accuracy: 0.9048 - 2s/epoch - 14ms/step\n","Epoch 23/100\n","168/168 - 2s - loss: 0.1143 - accuracy: 0.9966 - val_loss: 0.4333 - val_accuracy: 0.8214 - 2s/epoch - 14ms/step\n","Epoch 24/100\n","168/168 - 2s - loss: 0.1018 - accuracy: 0.9968 - val_loss: 1.0332 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 25/100\n","168/168 - 2s - loss: 0.1480 - accuracy: 0.9948 - val_loss: 1.4865 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 26/100\n","168/168 - 2s - loss: 0.0970 - accuracy: 0.9968 - val_loss: 1.1207 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 27/100\n","168/168 - 2s - loss: 0.1295 - accuracy: 0.9965 - val_loss: 0.5266 - val_accuracy: 0.8790 - 2s/epoch - 14ms/step\n","Epoch 28/100\n","168/168 - 2s - loss: 0.0496 - accuracy: 0.9989 - val_loss: 0.6533 - val_accuracy: 0.8968 - 2s/epoch - 14ms/step\n","Epoch 29/100\n","168/168 - 2s - loss: 0.0412 - accuracy: 0.9985 - val_loss: 0.5215 - val_accuracy: 0.8710 - 2s/epoch - 14ms/step\n","Epoch 30/100\n","168/168 - 2s - loss: 0.1064 - accuracy: 0.9966 - val_loss: 0.3721 - val_accuracy: 0.8313 - 2s/epoch - 14ms/step\n","Epoch 31/100\n","168/168 - 2s - loss: 0.0867 - accuracy: 0.9966 - val_loss: 0.7691 - val_accuracy: 0.8929 - 2s/epoch - 14ms/step\n","Epoch 32/100\n","168/168 - 2s - loss: 0.0485 - accuracy: 0.9987 - val_loss: 1.0679 - val_accuracy: 0.8948 - 2s/epoch - 14ms/step\n","Epoch 32: early stopping\n","42/42 - 0s - 220ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.5860 - accuracy: 0.7106 - val_loss: 0.4613 - val_accuracy: 0.8790 - 3s/epoch - 19ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 3.0036 - accuracy: 0.8768 - val_loss: 2.8098 - val_accuracy: 0.1964 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.7692 - accuracy: 0.9311 - val_loss: 3.6468 - val_accuracy: 0.1964 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 1.1227 - accuracy: 0.9612 - val_loss: 0.8100 - val_accuracy: 0.8651 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.6444 - accuracy: 0.9787 - val_loss: 1.2120 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4712 - accuracy: 0.9838 - val_loss: 1.0485 - val_accuracy: 0.7817 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.3272 - accuracy: 0.9896 - val_loss: 1.2750 - val_accuracy: 0.8591 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.2516 - accuracy: 0.9920 - val_loss: 1.2600 - val_accuracy: 0.6964 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2443 - accuracy: 0.9914 - val_loss: 1.6922 - val_accuracy: 0.6448 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2361 - accuracy: 0.9914 - val_loss: 1.6546 - val_accuracy: 0.8889 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.1806 - accuracy: 0.9933 - val_loss: 1.4112 - val_accuracy: 0.6766 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.1474 - accuracy: 0.9963 - val_loss: 1.5737 - val_accuracy: 0.7877 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1137 - accuracy: 0.9974 - val_loss: 1.2985 - val_accuracy: 0.8651 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.0801 - accuracy: 0.9976 - val_loss: 1.3936 - val_accuracy: 0.8651 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1600 - accuracy: 0.9950 - val_loss: 1.8950 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1392 - accuracy: 0.9959 - val_loss: 1.3372 - val_accuracy: 0.8829 - 2s/epoch - 14ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 194ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.2840 - accuracy: 0.7356 - val_loss: 0.4966 - val_accuracy: 0.6448 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.1496 - accuracy: 0.9319 - val_loss: 0.4502 - val_accuracy: 0.8413 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.1861 - accuracy: 0.9623 - val_loss: 1.6766 - val_accuracy: 0.5595 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.8834 - accuracy: 0.9709 - val_loss: 1.3579 - val_accuracy: 0.6964 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.6479 - accuracy: 0.9785 - val_loss: 1.3526 - val_accuracy: 0.8889 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4517 - accuracy: 0.9853 - val_loss: 2.7708 - val_accuracy: 0.2956 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.4192 - accuracy: 0.9860 - val_loss: 3.8928 - val_accuracy: 0.1944 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.3609 - accuracy: 0.9873 - val_loss: 1.4934 - val_accuracy: 0.8591 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2368 - accuracy: 0.9942 - val_loss: 1.5107 - val_accuracy: 0.8849 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.1915 - accuracy: 0.9940 - val_loss: 1.4296 - val_accuracy: 0.8512 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.2107 - accuracy: 0.9937 - val_loss: 2.0183 - val_accuracy: 0.8056 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2500 - accuracy: 0.9929 - val_loss: 2.5365 - val_accuracy: 0.4563 - 2s/epoch - 15ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.1432 - accuracy: 0.9961 - val_loss: 2.0302 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.1969 - accuracy: 0.9935 - val_loss: 1.6575 - val_accuracy: 0.8690 - 3s/epoch - 17ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1577 - accuracy: 0.9944 - val_loss: 1.6932 - val_accuracy: 0.8353 - 2s/epoch - 15ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.0850 - accuracy: 0.9976 - val_loss: 2.1767 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.1475 - accuracy: 0.9948 - val_loss: 2.1833 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 17: early stopping\n","42/42 - 0s - 220ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.0975 - accuracy: 0.7390 - val_loss: 1.4521 - val_accuracy: 0.1984 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.3334 - accuracy: 0.9101 - val_loss: 2.7616 - val_accuracy: 0.1012 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.2602 - accuracy: 0.9541 - val_loss: 1.3229 - val_accuracy: 0.5655 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.7747 - accuracy: 0.9735 - val_loss: 2.0149 - val_accuracy: 0.3929 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.7218 - accuracy: 0.9748 - val_loss: 1.4894 - val_accuracy: 0.8631 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4641 - accuracy: 0.9853 - val_loss: 1.5308 - val_accuracy: 0.8849 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.3147 - accuracy: 0.9888 - val_loss: 1.6481 - val_accuracy: 0.8810 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.3542 - accuracy: 0.9901 - val_loss: 1.8917 - val_accuracy: 0.8849 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2429 - accuracy: 0.9910 - val_loss: 2.0502 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2442 - accuracy: 0.9935 - val_loss: 2.3319 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.2179 - accuracy: 0.9933 - val_loss: 2.1306 - val_accuracy: 0.6210 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.3172 - accuracy: 0.9890 - val_loss: 3.1747 - val_accuracy: 0.4643 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1658 - accuracy: 0.9946 - val_loss: 2.3167 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1321 - accuracy: 0.9957 - val_loss: 2.1286 - val_accuracy: 0.8690 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.0871 - accuracy: 0.9976 - val_loss: 2.1793 - val_accuracy: 0.8730 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1522 - accuracy: 0.9948 - val_loss: 2.3156 - val_accuracy: 0.8631 - 2s/epoch - 14ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.1194 - accuracy: 0.9963 - val_loss: 2.1165 - val_accuracy: 0.8810 - 2s/epoch - 14ms/step\n","Epoch 18/100\n","168/168 - 2s - loss: 0.1735 - accuracy: 0.9948 - val_loss: 2.2182 - val_accuracy: 0.8651 - 2s/epoch - 14ms/step\n","Epoch 18: early stopping\n","42/42 - 0s - 227ms/epoch - 5ms/step\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","Epoch 1/100\n","168/168 - 3s - loss: 4.9362 - accuracy: 0.7550 - val_loss: 0.5649 - val_accuracy: 0.5694 - 3s/epoch - 18ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.5176 - accuracy: 0.9129 - val_loss: 1.3986 - val_accuracy: 0.3552 - 2s/epoch - 13ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.1827 - accuracy: 0.9638 - val_loss: 1.5933 - val_accuracy: 0.5575 - 2s/epoch - 12ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.6376 - accuracy: 0.9825 - val_loss: 1.3382 - val_accuracy: 0.5615 - 2s/epoch - 12ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.4638 - accuracy: 0.9901 - val_loss: 1.3865 - val_accuracy: 0.5774 - 2s/epoch - 12ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.2890 - accuracy: 0.9944 - val_loss: 1.4480 - val_accuracy: 0.5774 - 2s/epoch - 13ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.3039 - accuracy: 0.9931 - val_loss: 0.7882 - val_accuracy: 0.7460 - 2s/epoch - 12ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.1975 - accuracy: 0.9965 - val_loss: 1.1262 - val_accuracy: 0.5913 - 2s/epoch - 12ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.1850 - accuracy: 0.9968 - val_loss: 1.8063 - val_accuracy: 0.5774 - 2s/epoch - 12ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.1501 - accuracy: 0.9974 - val_loss: 0.7846 - val_accuracy: 0.8492 - 2s/epoch - 12ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.1721 - accuracy: 0.9955 - val_loss: 1.0503 - val_accuracy: 0.5774 - 2s/epoch - 13ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.1191 - accuracy: 0.9972 - val_loss: 0.7778 - val_accuracy: 0.8988 - 2s/epoch - 12ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1260 - accuracy: 0.9976 - val_loss: 1.7983 - val_accuracy: 0.5754 - 2s/epoch - 12ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.2024 - accuracy: 0.9946 - val_loss: 0.7183 - val_accuracy: 0.8571 - 2s/epoch - 12ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.0980 - accuracy: 0.9981 - val_loss: 0.7698 - val_accuracy: 0.8155 - 2s/epoch - 13ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.0865 - accuracy: 0.9978 - val_loss: 0.7521 - val_accuracy: 0.7083 - 2s/epoch - 13ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 203ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.4863 - accuracy: 0.7136 - val_loss: 0.3973 - val_accuracy: 0.8631 - 3s/epoch - 18ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.5919 - accuracy: 0.8994 - val_loss: 0.3669 - val_accuracy: 0.9444 - 2s/epoch - 13ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.4204 - accuracy: 0.9517 - val_loss: 1.9608 - val_accuracy: 0.2321 - 2s/epoch - 13ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.9126 - accuracy: 0.9733 - val_loss: 0.6287 - val_accuracy: 0.6429 - 2s/epoch - 12ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.6498 - accuracy: 0.9836 - val_loss: 0.3615 - val_accuracy: 0.8889 - 2s/epoch - 12ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.5000 - accuracy: 0.9875 - val_loss: 0.2577 - val_accuracy: 0.8968 - 2s/epoch - 12ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.3645 - accuracy: 0.9927 - val_loss: 0.2307 - val_accuracy: 0.8849 - 2s/epoch - 12ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.4613 - accuracy: 0.9892 - val_loss: 0.1763 - val_accuracy: 0.9107 - 2s/epoch - 12ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2925 - accuracy: 0.9938 - val_loss: 0.5028 - val_accuracy: 0.8095 - 2s/epoch - 12ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2670 - accuracy: 0.9931 - val_loss: 0.2673 - val_accuracy: 0.8849 - 2s/epoch - 13ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.2429 - accuracy: 0.9946 - val_loss: 0.8255 - val_accuracy: 0.9028 - 2s/epoch - 12ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.1931 - accuracy: 0.9961 - val_loss: 0.3985 - val_accuracy: 0.8869 - 2s/epoch - 12ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.2391 - accuracy: 0.9929 - val_loss: 0.2545 - val_accuracy: 0.8988 - 2s/epoch - 12ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.2229 - accuracy: 0.9948 - val_loss: 0.7360 - val_accuracy: 0.8988 - 2s/epoch - 12ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1642 - accuracy: 0.9966 - val_loss: 0.2736 - val_accuracy: 0.8988 - 2s/epoch - 12ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1066 - accuracy: 0.9985 - val_loss: 0.6331 - val_accuracy: 0.8948 - 2s/epoch - 12ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.1402 - accuracy: 0.9970 - val_loss: 0.6901 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 18/100\n","168/168 - 2s - loss: 0.1353 - accuracy: 0.9968 - val_loss: 0.5231 - val_accuracy: 0.8929 - 2s/epoch - 12ms/step\n","Epoch 19/100\n","168/168 - 2s - loss: 0.0739 - accuracy: 0.9991 - val_loss: 0.8156 - val_accuracy: 0.9028 - 2s/epoch - 12ms/step\n","Epoch 20/100\n","168/168 - 2s - loss: 0.1097 - accuracy: 0.9974 - val_loss: 0.8002 - val_accuracy: 0.8929 - 2s/epoch - 12ms/step\n","Epoch 21/100\n","168/168 - 2s - loss: 0.0828 - accuracy: 0.9987 - val_loss: 0.9049 - val_accuracy: 0.9028 - 2s/epoch - 12ms/step\n","Epoch 22/100\n","168/168 - 2s - loss: 0.0919 - accuracy: 0.9985 - val_loss: 0.6383 - val_accuracy: 0.9008 - 2s/epoch - 12ms/step\n","Epoch 23/100\n","168/168 - 2s - loss: 0.1069 - accuracy: 0.9976 - val_loss: 0.8233 - val_accuracy: 0.9028 - 2s/epoch - 12ms/step\n","Epoch 23: early stopping\n","42/42 - 0s - 179ms/epoch - 4ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.5920 - accuracy: 0.7020 - val_loss: 0.4661 - val_accuracy: 0.9048 - 3s/epoch - 18ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 3.2455 - accuracy: 0.8614 - val_loss: 0.3611 - val_accuracy: 0.9008 - 2s/epoch - 13ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.9237 - accuracy: 0.9308 - val_loss: 0.5904 - val_accuracy: 0.5794 - 2s/epoch - 13ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 1.1965 - accuracy: 0.9619 - val_loss: 0.4789 - val_accuracy: 0.8393 - 2s/epoch - 13ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.7416 - accuracy: 0.9812 - val_loss: 0.6182 - val_accuracy: 0.8472 - 2s/epoch - 13ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.5357 - accuracy: 0.9871 - val_loss: 0.7079 - val_accuracy: 0.6448 - 2s/epoch - 12ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.4873 - accuracy: 0.9877 - val_loss: 0.5196 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.2722 - accuracy: 0.9965 - val_loss: 0.6610 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2929 - accuracy: 0.9935 - val_loss: 0.6819 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2087 - accuracy: 0.9963 - val_loss: 0.6347 - val_accuracy: 0.8810 - 2s/epoch - 13ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.1819 - accuracy: 0.9970 - val_loss: 0.6282 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.1689 - accuracy: 0.9972 - val_loss: 0.6420 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1229 - accuracy: 0.9989 - val_loss: 0.5807 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.0808 - accuracy: 0.9993 - val_loss: 0.5247 - val_accuracy: 0.7817 - 2s/epoch - 13ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1006 - accuracy: 0.9989 - val_loss: 0.5884 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1579 - accuracy: 0.9961 - val_loss: 0.6579 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 17/100\n","168/168 - 2s - loss: 0.0788 - accuracy: 0.9985 - val_loss: 0.7492 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 17: early stopping\n","42/42 - 0s - 191ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 4.7473 - accuracy: 0.7623 - val_loss: 0.3971 - val_accuracy: 0.8948 - 3s/epoch - 18ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 1.9023 - accuracy: 0.9364 - val_loss: 0.4468 - val_accuracy: 0.9028 - 2s/epoch - 12ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.2763 - accuracy: 0.9565 - val_loss: 0.8321 - val_accuracy: 0.4147 - 2s/epoch - 12ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.8654 - accuracy: 0.9716 - val_loss: 0.5883 - val_accuracy: 0.8929 - 2s/epoch - 12ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.6314 - accuracy: 0.9813 - val_loss: 0.6107 - val_accuracy: 0.8849 - 2s/epoch - 12ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.5619 - accuracy: 0.9840 - val_loss: 0.5325 - val_accuracy: 0.8750 - 2s/epoch - 13ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.4243 - accuracy: 0.9894 - val_loss: 0.5874 - val_accuracy: 0.8770 - 2s/epoch - 12ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.3475 - accuracy: 0.9910 - val_loss: 0.8450 - val_accuracy: 0.8869 - 2s/epoch - 12ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2541 - accuracy: 0.9944 - val_loss: 0.8286 - val_accuracy: 0.7361 - 2s/epoch - 13ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2211 - accuracy: 0.9965 - val_loss: 0.8294 - val_accuracy: 0.8770 - 2s/epoch - 15ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.2394 - accuracy: 0.9944 - val_loss: 1.0056 - val_accuracy: 0.8869 - 3s/epoch - 17ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2165 - accuracy: 0.9955 - val_loss: 1.1522 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.2168 - accuracy: 0.9951 - val_loss: 1.0040 - val_accuracy: 0.7599 - 2s/epoch - 13ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1518 - accuracy: 0.9968 - val_loss: 1.0091 - val_accuracy: 0.8790 - 2s/epoch - 13ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1748 - accuracy: 0.9955 - val_loss: 0.9807 - val_accuracy: 0.8889 - 2s/epoch - 12ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1220 - accuracy: 0.9981 - val_loss: 1.0415 - val_accuracy: 0.8730 - 2s/epoch - 13ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 192ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.7023 - accuracy: 0.6709 - val_loss: 0.4020 - val_accuracy: 0.8849 - 3s/epoch - 18ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.1441 - accuracy: 0.9220 - val_loss: 0.5358 - val_accuracy: 0.8770 - 2s/epoch - 13ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.3049 - accuracy: 0.9560 - val_loss: 0.8417 - val_accuracy: 0.8036 - 2s/epoch - 13ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.8666 - accuracy: 0.9737 - val_loss: 1.3518 - val_accuracy: 0.3690 - 2s/epoch - 13ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.6139 - accuracy: 0.9851 - val_loss: 0.9291 - val_accuracy: 0.8849 - 2s/epoch - 12ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4005 - accuracy: 0.9924 - val_loss: 0.9952 - val_accuracy: 0.8869 - 2s/epoch - 13ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.2400 - accuracy: 0.9959 - val_loss: 1.1208 - val_accuracy: 0.8829 - 2s/epoch - 13ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.2084 - accuracy: 0.9953 - val_loss: 1.1306 - val_accuracy: 0.8869 - 2s/epoch - 13ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.1633 - accuracy: 0.9976 - val_loss: 1.2890 - val_accuracy: 0.8988 - 2s/epoch - 13ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.1509 - accuracy: 0.9970 - val_loss: 1.3934 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.1376 - accuracy: 0.9987 - val_loss: 1.2777 - val_accuracy: 0.7103 - 2s/epoch - 13ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.0913 - accuracy: 0.9987 - val_loss: 1.2786 - val_accuracy: 0.8730 - 2s/epoch - 13ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1123 - accuracy: 0.9972 - val_loss: 1.3636 - val_accuracy: 0.7798 - 2s/epoch - 13ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.0980 - accuracy: 0.9989 - val_loss: 1.2663 - val_accuracy: 0.8869 - 2s/epoch - 13ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.0981 - accuracy: 0.9987 - val_loss: 1.2681 - val_accuracy: 0.8869 - 2s/epoch - 13ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.0674 - accuracy: 0.9994 - val_loss: 1.5405 - val_accuracy: 0.9028 - 2s/epoch - 13ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 205ms/epoch - 5ms/step\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","Epoch 1/100\n","168/168 - 4s - loss: 4.4262 - accuracy: 0.7929 - val_loss: 0.7510 - val_accuracy: 0.5853 - 4s/epoch - 24ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.5593 - accuracy: 0.9407 - val_loss: 0.5094 - val_accuracy: 0.8988 - 3s/epoch - 17ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 0.6507 - accuracy: 0.9769 - val_loss: 1.9520 - val_accuracy: 0.6548 - 3s/epoch - 17ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.4935 - accuracy: 0.9821 - val_loss: 1.6631 - val_accuracy: 0.6667 - 3s/epoch - 18ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.3436 - accuracy: 0.9881 - val_loss: 1.3954 - val_accuracy: 0.5913 - 3s/epoch - 18ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.2468 - accuracy: 0.9931 - val_loss: 1.4809 - val_accuracy: 0.6071 - 3s/epoch - 17ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.2446 - accuracy: 0.9907 - val_loss: 13.6559 - val_accuracy: 0.1964 - 3s/epoch - 18ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.2838 - accuracy: 0.9894 - val_loss: 1.1629 - val_accuracy: 0.8829 - 3s/epoch - 17ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.2675 - accuracy: 0.9899 - val_loss: 0.9595 - val_accuracy: 0.8810 - 3s/epoch - 18ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.0995 - accuracy: 0.9974 - val_loss: 2.7907 - val_accuracy: 0.5655 - 3s/epoch - 18ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.0902 - accuracy: 0.9966 - val_loss: 2.1599 - val_accuracy: 0.5754 - 3s/epoch - 18ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.0945 - accuracy: 0.9966 - val_loss: 1.5309 - val_accuracy: 0.7222 - 3s/epoch - 18ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.1790 - accuracy: 0.9942 - val_loss: 1.3304 - val_accuracy: 0.6190 - 3s/epoch - 18ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.1282 - accuracy: 0.9957 - val_loss: 1.0261 - val_accuracy: 0.6627 - 3s/epoch - 18ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.2455 - accuracy: 0.9918 - val_loss: 0.7230 - val_accuracy: 0.8968 - 3s/epoch - 18ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.1063 - accuracy: 0.9968 - val_loss: 1.6655 - val_accuracy: 0.6567 - 3s/epoch - 18ms/step\n","Epoch 17/100\n","168/168 - 3s - loss: 0.0955 - accuracy: 0.9974 - val_loss: 1.1672 - val_accuracy: 0.6825 - 3s/epoch - 18ms/step\n","Epoch 17: early stopping\n","42/42 - 0s - 280ms/epoch - 7ms/step\n","Epoch 1/100\n","168/168 - 4s - loss: 5.2975 - accuracy: 0.7302 - val_loss: 1.2934 - val_accuracy: 0.1964 - 4s/epoch - 23ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 2.1102 - accuracy: 0.9151 - val_loss: 1.7711 - val_accuracy: 0.3115 - 3s/epoch - 18ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 1.0571 - accuracy: 0.9623 - val_loss: 0.7453 - val_accuracy: 0.8591 - 3s/epoch - 18ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.7223 - accuracy: 0.9770 - val_loss: 1.1192 - val_accuracy: 0.6687 - 3s/epoch - 18ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.6756 - accuracy: 0.9757 - val_loss: 1.3642 - val_accuracy: 0.6647 - 3s/epoch - 18ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.3300 - accuracy: 0.9892 - val_loss: 1.1884 - val_accuracy: 0.8849 - 3s/epoch - 18ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.3803 - accuracy: 0.9890 - val_loss: 1.3761 - val_accuracy: 0.8849 - 3s/epoch - 18ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.3333 - accuracy: 0.9884 - val_loss: 0.9183 - val_accuracy: 0.8710 - 3s/epoch - 18ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.1469 - accuracy: 0.9944 - val_loss: 1.4552 - val_accuracy: 0.8770 - 3s/epoch - 18ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.1746 - accuracy: 0.9938 - val_loss: 2.7346 - val_accuracy: 0.5337 - 3s/epoch - 18ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.2714 - accuracy: 0.9897 - val_loss: 0.9619 - val_accuracy: 0.8730 - 3s/epoch - 18ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.2442 - accuracy: 0.9910 - val_loss: 1.0298 - val_accuracy: 0.8730 - 3s/epoch - 18ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.1514 - accuracy: 0.9925 - val_loss: 1.2396 - val_accuracy: 0.8750 - 3s/epoch - 18ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.3701 - accuracy: 0.9920 - val_loss: 1.0188 - val_accuracy: 0.8631 - 3s/epoch - 18ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.1986 - accuracy: 0.9931 - val_loss: 1.5337 - val_accuracy: 0.8710 - 3s/epoch - 18ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.1467 - accuracy: 0.9951 - val_loss: 1.7078 - val_accuracy: 0.8849 - 3s/epoch - 18ms/step\n","Epoch 17/100\n","168/168 - 3s - loss: 0.1548 - accuracy: 0.9942 - val_loss: 1.3415 - val_accuracy: 0.8849 - 3s/epoch - 18ms/step\n","Epoch 18/100\n","168/168 - 3s - loss: 0.2271 - accuracy: 0.9950 - val_loss: 1.0202 - val_accuracy: 0.8770 - 3s/epoch - 18ms/step\n","Epoch 18: early stopping\n","42/42 - 0s - 248ms/epoch - 6ms/step\n","Epoch 1/100\n","168/168 - 4s - loss: 5.4050 - accuracy: 0.7132 - val_loss: 0.3981 - val_accuracy: 0.8829 - 4s/epoch - 23ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 2.2953 - accuracy: 0.9101 - val_loss: 0.5002 - val_accuracy: 0.8710 - 3s/epoch - 18ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 1.0245 - accuracy: 0.9647 - val_loss: 1.3216 - val_accuracy: 0.3075 - 3s/epoch - 18ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.6151 - accuracy: 0.9787 - val_loss: 0.8218 - val_accuracy: 0.8770 - 3s/epoch - 18ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.5311 - accuracy: 0.9825 - val_loss: 0.9734 - val_accuracy: 0.8849 - 3s/epoch - 18ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.4018 - accuracy: 0.9869 - val_loss: 1.8797 - val_accuracy: 0.9028 - 3s/epoch - 18ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.2403 - accuracy: 0.9912 - val_loss: 1.6702 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.2529 - accuracy: 0.9918 - val_loss: 1.2435 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.2572 - accuracy: 0.9912 - val_loss: 1.7088 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.1800 - accuracy: 0.9942 - val_loss: 1.5345 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.1522 - accuracy: 0.9935 - val_loss: 1.6561 - val_accuracy: 0.8810 - 3s/epoch - 18ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.1809 - accuracy: 0.9938 - val_loss: 1.4381 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.2163 - accuracy: 0.9918 - val_loss: 1.3736 - val_accuracy: 0.8611 - 3s/epoch - 18ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.2044 - accuracy: 0.9942 - val_loss: 1.3642 - val_accuracy: 0.8810 - 3s/epoch - 18ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.0836 - accuracy: 0.9966 - val_loss: 1.4186 - val_accuracy: 0.8770 - 3s/epoch - 18ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.0511 - accuracy: 0.9983 - val_loss: 1.9080 - val_accuracy: 0.8829 - 3s/epoch - 18ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 254ms/epoch - 6ms/step\n","Epoch 1/100\n","168/168 - 4s - loss: 5.0616 - accuracy: 0.7434 - val_loss: 0.3331 - val_accuracy: 0.9028 - 4s/epoch - 23ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.6614 - accuracy: 0.9491 - val_loss: 0.3437 - val_accuracy: 0.8829 - 3s/epoch - 18ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 1.1200 - accuracy: 0.9617 - val_loss: 0.6211 - val_accuracy: 0.8393 - 3s/epoch - 18ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.7316 - accuracy: 0.9742 - val_loss: 0.6804 - val_accuracy: 0.8710 - 3s/epoch - 18ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.5211 - accuracy: 0.9830 - val_loss: 0.8640 - val_accuracy: 0.8889 - 3s/epoch - 18ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.4220 - accuracy: 0.9860 - val_loss: 0.8779 - val_accuracy: 0.8234 - 3s/epoch - 18ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.3595 - accuracy: 0.9866 - val_loss: 1.1635 - val_accuracy: 0.6032 - 3s/epoch - 18ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.1994 - accuracy: 0.9940 - val_loss: 1.3022 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.2321 - accuracy: 0.9920 - val_loss: 1.0463 - val_accuracy: 0.8373 - 3s/epoch - 18ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.3905 - accuracy: 0.9869 - val_loss: 1.6988 - val_accuracy: 0.9028 - 3s/epoch - 18ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.2559 - accuracy: 0.9914 - val_loss: 1.0265 - val_accuracy: 0.8750 - 3s/epoch - 18ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.2513 - accuracy: 0.9927 - val_loss: 1.1380 - val_accuracy: 0.8631 - 3s/epoch - 18ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.1261 - accuracy: 0.9953 - val_loss: 1.1423 - val_accuracy: 0.8810 - 3s/epoch - 18ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.1480 - accuracy: 0.9953 - val_loss: 2.7228 - val_accuracy: 0.3274 - 3s/epoch - 18ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.2361 - accuracy: 0.9929 - val_loss: 1.7774 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.1934 - accuracy: 0.9940 - val_loss: 1.0860 - val_accuracy: 0.8810 - 3s/epoch - 18ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 278ms/epoch - 7ms/step\n","Epoch 1/100\n","168/168 - 4s - loss: 5.5432 - accuracy: 0.6970 - val_loss: 0.4875 - val_accuracy: 0.8214 - 4s/epoch - 23ms/step\n","Epoch 2/100\n","168/168 - 3s - loss: 1.9337 - accuracy: 0.9241 - val_loss: 1.1694 - val_accuracy: 0.3175 - 3s/epoch - 17ms/step\n","Epoch 3/100\n","168/168 - 3s - loss: 1.0096 - accuracy: 0.9662 - val_loss: 0.5243 - val_accuracy: 0.8750 - 3s/epoch - 17ms/step\n","Epoch 4/100\n","168/168 - 3s - loss: 0.4024 - accuracy: 0.9862 - val_loss: 1.0228 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 5/100\n","168/168 - 3s - loss: 0.3808 - accuracy: 0.9873 - val_loss: 0.8966 - val_accuracy: 0.8750 - 3s/epoch - 17ms/step\n","Epoch 6/100\n","168/168 - 3s - loss: 0.4620 - accuracy: 0.9862 - val_loss: 0.6472 - val_accuracy: 0.8770 - 3s/epoch - 18ms/step\n","Epoch 7/100\n","168/168 - 3s - loss: 0.2935 - accuracy: 0.9881 - val_loss: 1.1840 - val_accuracy: 0.8869 - 3s/epoch - 18ms/step\n","Epoch 8/100\n","168/168 - 3s - loss: 0.2133 - accuracy: 0.9931 - val_loss: 1.0300 - val_accuracy: 0.8869 - 3s/epoch - 17ms/step\n","Epoch 9/100\n","168/168 - 3s - loss: 0.2767 - accuracy: 0.9910 - val_loss: 1.5336 - val_accuracy: 0.8968 - 3s/epoch - 17ms/step\n","Epoch 10/100\n","168/168 - 3s - loss: 0.1616 - accuracy: 0.9929 - val_loss: 1.2419 - val_accuracy: 0.8313 - 3s/epoch - 18ms/step\n","Epoch 11/100\n","168/168 - 3s - loss: 0.1485 - accuracy: 0.9942 - val_loss: 1.4960 - val_accuracy: 0.8829 - 3s/epoch - 17ms/step\n","Epoch 12/100\n","168/168 - 3s - loss: 0.2108 - accuracy: 0.9918 - val_loss: 5.4064 - val_accuracy: 0.5079 - 3s/epoch - 17ms/step\n","Epoch 13/100\n","168/168 - 3s - loss: 0.3974 - accuracy: 0.9892 - val_loss: 1.7349 - val_accuracy: 0.8869 - 3s/epoch - 17ms/step\n","Epoch 14/100\n","168/168 - 3s - loss: 0.0942 - accuracy: 0.9965 - val_loss: 1.2649 - val_accuracy: 0.8452 - 3s/epoch - 18ms/step\n","Epoch 15/100\n","168/168 - 3s - loss: 0.1126 - accuracy: 0.9966 - val_loss: 1.3162 - val_accuracy: 0.8750 - 3s/epoch - 18ms/step\n","Epoch 16/100\n","168/168 - 3s - loss: 0.1094 - accuracy: 0.9972 - val_loss: 1.8707 - val_accuracy: 0.8869 - 3s/epoch - 17ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 314ms/epoch - 7ms/step\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","Epoch 1/100\n","168/168 - 3s - loss: 4.6271 - accuracy: 0.7850 - val_loss: 0.4272 - val_accuracy: 0.8333 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.0504 - accuracy: 0.9194 - val_loss: 2.2536 - val_accuracy: 0.5615 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.1177 - accuracy: 0.9610 - val_loss: 2.2260 - val_accuracy: 0.5595 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.6857 - accuracy: 0.9778 - val_loss: 3.1131 - val_accuracy: 0.5437 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.4785 - accuracy: 0.9853 - val_loss: 4.0084 - val_accuracy: 0.4742 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.4782 - accuracy: 0.9834 - val_loss: 2.9112 - val_accuracy: 0.5575 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.3136 - accuracy: 0.9905 - val_loss: 4.5986 - val_accuracy: 0.4623 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.3310 - accuracy: 0.9897 - val_loss: 2.8020 - val_accuracy: 0.7619 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2262 - accuracy: 0.9946 - val_loss: 3.2905 - val_accuracy: 0.4623 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.3349 - accuracy: 0.9896 - val_loss: 3.1927 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.1723 - accuracy: 0.9951 - val_loss: 2.4235 - val_accuracy: 0.6012 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2021 - accuracy: 0.9944 - val_loss: 3.2694 - val_accuracy: 0.4683 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1222 - accuracy: 0.9970 - val_loss: 3.3603 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1472 - accuracy: 0.9957 - val_loss: 3.8115 - val_accuracy: 0.3393 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.2231 - accuracy: 0.9929 - val_loss: 2.9956 - val_accuracy: 0.6964 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1483 - accuracy: 0.9953 - val_loss: 3.2555 - val_accuracy: 0.5337 - 2s/epoch - 14ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 224ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.5181 - accuracy: 0.7274 - val_loss: 0.4445 - val_accuracy: 0.8254 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.9898 - accuracy: 0.8869 - val_loss: 0.4525 - val_accuracy: 0.8036 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.8083 - accuracy: 0.9369 - val_loss: 0.5076 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 1.0231 - accuracy: 0.9675 - val_loss: 0.7659 - val_accuracy: 0.8690 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.8186 - accuracy: 0.9741 - val_loss: 0.9892 - val_accuracy: 0.8333 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.5464 - accuracy: 0.9843 - val_loss: 1.6335 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.4522 - accuracy: 0.9853 - val_loss: 1.2181 - val_accuracy: 0.8790 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.4283 - accuracy: 0.9873 - val_loss: 1.2768 - val_accuracy: 0.7877 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.3844 - accuracy: 0.9877 - val_loss: 1.4756 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.3958 - accuracy: 0.9882 - val_loss: 1.5647 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.3124 - accuracy: 0.9905 - val_loss: 1.5162 - val_accuracy: 0.7520 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.3045 - accuracy: 0.9896 - val_loss: 1.6913 - val_accuracy: 0.7044 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1915 - accuracy: 0.9946 - val_loss: 1.7372 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1850 - accuracy: 0.9950 - val_loss: 1.6015 - val_accuracy: 0.8829 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.2413 - accuracy: 0.9927 - val_loss: 2.1641 - val_accuracy: 0.4861 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.2667 - accuracy: 0.9923 - val_loss: 1.4159 - val_accuracy: 0.7996 - 2s/epoch - 14ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 228ms/epoch - 5ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.2718 - accuracy: 0.7298 - val_loss: 0.6329 - val_accuracy: 0.5417 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.6676 - accuracy: 0.8972 - val_loss: 2.7367 - val_accuracy: 0.1944 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.4021 - accuracy: 0.9528 - val_loss: 1.0672 - val_accuracy: 0.7044 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.8496 - accuracy: 0.9739 - val_loss: 1.0406 - val_accuracy: 0.8909 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.6775 - accuracy: 0.9770 - val_loss: 0.9901 - val_accuracy: 0.8750 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.3772 - accuracy: 0.9890 - val_loss: 1.0411 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.3749 - accuracy: 0.9896 - val_loss: 1.0531 - val_accuracy: 0.8810 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.3706 - accuracy: 0.9890 - val_loss: 1.0621 - val_accuracy: 0.8750 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2922 - accuracy: 0.9922 - val_loss: 1.1682 - val_accuracy: 0.8512 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2007 - accuracy: 0.9942 - val_loss: 1.5318 - val_accuracy: 0.5159 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.1707 - accuracy: 0.9955 - val_loss: 1.1463 - val_accuracy: 0.8829 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2247 - accuracy: 0.9937 - val_loss: 1.2150 - val_accuracy: 0.8730 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.2167 - accuracy: 0.9933 - val_loss: 1.2852 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1860 - accuracy: 0.9935 - val_loss: 1.4243 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1432 - accuracy: 0.9961 - val_loss: 1.3233 - val_accuracy: 0.8829 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1363 - accuracy: 0.9955 - val_loss: 1.3894 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 240ms/epoch - 6ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.3116 - accuracy: 0.7173 - val_loss: 0.4048 - val_accuracy: 0.9028 - 3s/epoch - 19ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 2.3014 - accuracy: 0.9265 - val_loss: 0.8806 - val_accuracy: 0.5714 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 1.5131 - accuracy: 0.9533 - val_loss: 1.1256 - val_accuracy: 0.6389 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 1.1662 - accuracy: 0.9644 - val_loss: 0.9912 - val_accuracy: 0.7917 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.8842 - accuracy: 0.9718 - val_loss: 0.9532 - val_accuracy: 0.8909 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.7137 - accuracy: 0.9802 - val_loss: 1.0661 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.5724 - accuracy: 0.9812 - val_loss: 1.5325 - val_accuracy: 0.9008 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.4465 - accuracy: 0.9862 - val_loss: 1.4635 - val_accuracy: 0.8909 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.2911 - accuracy: 0.9922 - val_loss: 1.6139 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.3254 - accuracy: 0.9884 - val_loss: 1.4047 - val_accuracy: 0.8532 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.3206 - accuracy: 0.9901 - val_loss: 1.4279 - val_accuracy: 0.8690 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.2021 - accuracy: 0.9937 - val_loss: 1.6467 - val_accuracy: 0.8512 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.2040 - accuracy: 0.9938 - val_loss: 1.6532 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1831 - accuracy: 0.9940 - val_loss: 1.6934 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.2310 - accuracy: 0.9918 - val_loss: 1.6037 - val_accuracy: 0.8829 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1558 - accuracy: 0.9955 - val_loss: 1.7104 - val_accuracy: 0.9028 - 2s/epoch - 14ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 369ms/epoch - 9ms/step\n","Epoch 1/100\n","168/168 - 3s - loss: 5.2647 - accuracy: 0.7196 - val_loss: 0.8754 - val_accuracy: 0.1667 - 3s/epoch - 20ms/step\n","Epoch 2/100\n","168/168 - 2s - loss: 1.9310 - accuracy: 0.9269 - val_loss: 0.9973 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 3/100\n","168/168 - 2s - loss: 0.9406 - accuracy: 0.9696 - val_loss: 2.1832 - val_accuracy: 0.4107 - 2s/epoch - 14ms/step\n","Epoch 4/100\n","168/168 - 2s - loss: 0.5455 - accuracy: 0.9841 - val_loss: 2.4536 - val_accuracy: 0.4921 - 2s/epoch - 14ms/step\n","Epoch 5/100\n","168/168 - 2s - loss: 0.6129 - accuracy: 0.9810 - val_loss: 1.6247 - val_accuracy: 0.8770 - 2s/epoch - 14ms/step\n","Epoch 6/100\n","168/168 - 2s - loss: 0.3698 - accuracy: 0.9901 - val_loss: 1.6913 - val_accuracy: 0.8591 - 2s/epoch - 14ms/step\n","Epoch 7/100\n","168/168 - 2s - loss: 0.2624 - accuracy: 0.9920 - val_loss: 1.9008 - val_accuracy: 0.8591 - 2s/epoch - 14ms/step\n","Epoch 8/100\n","168/168 - 2s - loss: 0.2643 - accuracy: 0.9914 - val_loss: 1.8545 - val_accuracy: 0.8671 - 2s/epoch - 14ms/step\n","Epoch 9/100\n","168/168 - 2s - loss: 0.3084 - accuracy: 0.9918 - val_loss: 3.0886 - val_accuracy: 0.4444 - 2s/epoch - 14ms/step\n","Epoch 10/100\n","168/168 - 2s - loss: 0.2125 - accuracy: 0.9935 - val_loss: 2.0418 - val_accuracy: 0.8869 - 2s/epoch - 14ms/step\n","Epoch 11/100\n","168/168 - 2s - loss: 0.1901 - accuracy: 0.9950 - val_loss: 1.9291 - val_accuracy: 0.8849 - 2s/epoch - 14ms/step\n","Epoch 12/100\n","168/168 - 2s - loss: 0.1642 - accuracy: 0.9963 - val_loss: 3.0717 - val_accuracy: 0.5000 - 2s/epoch - 14ms/step\n","Epoch 13/100\n","168/168 - 2s - loss: 0.1616 - accuracy: 0.9953 - val_loss: 1.7913 - val_accuracy: 0.8750 - 2s/epoch - 14ms/step\n","Epoch 14/100\n","168/168 - 2s - loss: 0.1368 - accuracy: 0.9957 - val_loss: 1.9185 - val_accuracy: 0.8810 - 2s/epoch - 15ms/step\n","Epoch 15/100\n","168/168 - 2s - loss: 0.1645 - accuracy: 0.9957 - val_loss: 2.2318 - val_accuracy: 0.5754 - 2s/epoch - 14ms/step\n","Epoch 16/100\n","168/168 - 2s - loss: 0.1284 - accuracy: 0.9963 - val_loss: 1.9408 - val_accuracy: 0.8849 - 2s/epoch - 14ms/step\n","Epoch 16: early stopping\n","42/42 - 0s - 219ms/epoch - 5ms/step\n","Epoch 1/100\n","210/210 - 5s - loss: 4.2815 - accuracy: 0.7830 - val_loss: 0.3628 - val_accuracy: 0.8829 - 5s/epoch - 23ms/step\n","Epoch 2/100\n","210/210 - 4s - loss: 1.3707 - accuracy: 0.9454 - val_loss: 0.8302 - val_accuracy: 0.8869 - 4s/epoch - 18ms/step\n","Epoch 3/100\n","210/210 - 4s - loss: 0.8725 - accuracy: 0.9675 - val_loss: 1.1431 - val_accuracy: 0.8849 - 4s/epoch - 17ms/step\n","Epoch 4/100\n","210/210 - 4s - loss: 0.7016 - accuracy: 0.9763 - val_loss: 1.5029 - val_accuracy: 0.8929 - 4s/epoch - 18ms/step\n","Epoch 5/100\n","210/210 - 4s - loss: 0.5793 - accuracy: 0.9798 - val_loss: 1.2000 - val_accuracy: 0.8849 - 4s/epoch - 18ms/step\n","Epoch 6/100\n","210/210 - 4s - loss: 0.4257 - accuracy: 0.9846 - val_loss: 1.3681 - val_accuracy: 0.5238 - 4s/epoch - 18ms/step\n","Epoch 7/100\n","210/210 - 4s - loss: 0.2670 - accuracy: 0.9894 - val_loss: 1.2647 - val_accuracy: 0.8413 - 4s/epoch - 17ms/step\n","Epoch 8/100\n","210/210 - 4s - loss: 0.3089 - accuracy: 0.9896 - val_loss: 1.5373 - val_accuracy: 0.8810 - 4s/epoch - 17ms/step\n","Epoch 9/100\n","210/210 - 4s - loss: 0.2956 - accuracy: 0.9907 - val_loss: 2.3179 - val_accuracy: 0.9028 - 4s/epoch - 18ms/step\n","Epoch 10/100\n","210/210 - 4s - loss: 0.2015 - accuracy: 0.9937 - val_loss: 1.5225 - val_accuracy: 0.8849 - 4s/epoch - 17ms/step\n","Epoch 11/100\n","210/210 - 4s - loss: 0.2360 - accuracy: 0.9924 - val_loss: 2.0072 - val_accuracy: 0.8968 - 4s/epoch - 18ms/step\n","Epoch 12/100\n","210/210 - 4s - loss: 0.2423 - accuracy: 0.9903 - val_loss: 1.3722 - val_accuracy: 0.8135 - 4s/epoch - 18ms/step\n","Epoch 13/100\n","210/210 - 4s - loss: 0.1383 - accuracy: 0.9954 - val_loss: 1.8108 - val_accuracy: 0.8869 - 4s/epoch - 17ms/step\n","Epoch 14/100\n","210/210 - 4s - loss: 0.3300 - accuracy: 0.9888 - val_loss: 1.1703 - val_accuracy: 0.8512 - 4s/epoch - 17ms/step\n","Epoch 15/100\n","210/210 - 4s - loss: 0.3235 - accuracy: 0.9888 - val_loss: 1.3647 - val_accuracy: 0.8611 - 4s/epoch - 18ms/step\n","Epoch 16/100\n","210/210 - 4s - loss: 0.1645 - accuracy: 0.9951 - val_loss: 1.7219 - val_accuracy: 0.6508 - 4s/epoch - 17ms/step\n","Epoch 16: early stopping\n","0.779340 (0.134595) with: OrderedDict([('model__F1', 16), ('model__F2', 32), ('model__kernelLength', 64), ('model__norm_rate', 1.0)])\n","0.661857 (0.141957) with: OrderedDict([('model__F1', 16), ('model__F2', 16), ('model__kernelLength', 512), ('model__norm_rate', 5.0)])\n","0.721300 (0.097232) with: OrderedDict([('model__F1', 8), ('model__F2', 32), ('model__kernelLength', 128), ('model__norm_rate', 1.0)])\n","0.778931 (0.107911) with: OrderedDict([('model__F1', 16), ('model__F2', 32), ('model__kernelLength', 32), ('model__norm_rate', 1.0)])\n","0.815659 (0.090022) with: OrderedDict([('model__F1', 16), ('model__F2', 32), ('model__kernelLength', 256), ('model__norm_rate', 5.0)])\n","0.804747 (0.058861) with: OrderedDict([('model__F1', 8), ('model__F2', 16), ('model__kernelLength', 32), ('model__norm_rate', 5.0)])\n","0.676507 (0.142422) with: OrderedDict([('model__F1', 8), ('model__F2', 32), ('model__kernelLength', 128), ('model__norm_rate', 1.0)])\n","0.826241 (0.072809) with: OrderedDict([('model__F1', 8), ('model__F2', 16), ('model__kernelLength', 32), ('model__norm_rate', 0.5)])\n","0.840125 (0.053815) with: OrderedDict([('model__F1', 16), ('model__F2', 32), ('model__kernelLength', 128), ('model__norm_rate', 5.0)])\n","0.785361 (0.126744) with: OrderedDict([('model__F1', 8), ('model__F2', 16), ('model__kernelLength', 128), ('model__norm_rate', 1.0)])\n","The Best Score: 0.8401248425534762\n","The Best Params: OrderedDict([('model__F1', 16), ('model__F2', 32), ('model__kernelLength', 128), ('model__norm_rate', 5.0)])\n"]}]},{"cell_type":"markdown","source":["**Predicting and evaluating on the test set(sample-wise and subject-wise)**"],"metadata":{"id":"WIrXP1fRQp0P"}},{"cell_type":"code","source":["#### Test Prediction ####\n","pred = search.predict(X_test)\n","acc  = np.mean(pred == Y_test)\n","print(\"The sample test acc is:\", acc)\n","### Calculate Subject accuracy and F-measure\n","pred_proba = search.predict_proba(X_test)\n","sub_acc_max , subF2_max = subject_classification(Y_test, pred_proba, Group_test, calculate_type = 'max_vote')\n","print(\"Subject Accuracy MaxVote:\",sub_acc_max)\n","print(\"Subject F2 MaxVote:\",subF2_max)\n","print(\"------------------------------\")\n","sub_acc_mean , subF2_mean = subject_classification(Y_test, pred_proba, Group_test, calculate_type = 'mean')\n","print(\"Subject Accuracy Mean:\",sub_acc_mean)\n","print(\"Subject F2 Mean:\",subF2_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434},"id":"qBLF1ILwLFrW","executionInfo":{"status":"ok","timestamp":1674642960078,"user_tz":-210,"elapsed":1404,"user":{"displayName":"Ali Amini","userId":"04196589200907759172"}},"outputId":"98bee13e-9df1-45aa-e2a2-41defe100c07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23/23 - 0s - 130ms/epoch - 6ms/step\n","The sample test acc is: 0.8387096774193549\n","23/23 - 0s - 124ms/epoch - 5ms/step\n","Subject Accuracy MaxVote: 0.8333333333333334\n","Subject F2 MaxVote: 0.7575757575757576\n","------------------------------\n","Subject Accuracy Mean: 0.8333333333333334\n","Subject F2 Mean: 0.7575757575757576\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 3 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Changing the directory**"
      ],
      "metadata": {
        "id": "z95WMSwSA10a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUdbtrCci6Hl",
        "outputId": "5cec64b5-a5df-41b4-fc7c-d05b0ef67186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NasrAbadi/EEG Time Series /Four Sec without Overlap/With Baseline/Simple Train Test Split\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/NasrAbadi/EEG Time Series /Four Sec without Overlap/With Baseline/Simple Train Test Split'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing Required Packages**"
      ],
      "metadata": {
        "id": "OdmxZ6kpA6Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "!pip install pyriemann"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K-PC2L6jpnk",
        "outputId": "65e03df3-7294-480b-c8cc-cbd8fc887c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.8/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyriemann in /usr/local/lib/python3.8/dist-packages (0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from pyriemann) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pyriemann) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyriemann) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pyriemann) (1.3.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pyriemann) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pyriemann) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pyriemann) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pyriemann) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->pyriemann) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change the channels to first**"
      ],
      "metadata": {
        "id": "mPmUqJbxBAhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_first')"
      ],
      "metadata": {
        "id": "Jmnjkxevjrmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the Model**"
      ],
      "metadata": {
        "id": "LDax-Ln0BCrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout, multiply,LSTM\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import SpatialDropout2D\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.layers import Input, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.optimizers.experimental import AdamW\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import fbeta_score\n",
        "import math\n",
        "import gc\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from skopt.utils import use_named_args\n",
        "from skopt import gp_minimize\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def create_model(kernelLength = 32, nb_classes = 2, Chans = 19, Samples = 512,   \n",
        "                dropoutRate = 0.5 , F1 = 8, D = 2, F2 = 16, norm_rate = 0.25,\n",
        "                dropoutType = 'Dropout', optimizer_type = 'Adam', lr=0.0005, **kwargs):\n",
        "  \n",
        "  K.clear_session()\n",
        "  gc.collect()\n",
        "  if dropoutType == 'SpatialDropout2D':\n",
        "      dropoutType = SpatialDropout2D\n",
        "  elif dropoutType == 'Dropout':\n",
        "      dropoutType = Dropout\n",
        "  else:\n",
        "      raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
        "                        'or Dropout, passed as a string.')\n",
        "  \n",
        "  input1   = Input(shape = (1, Chans, Samples))\n",
        "\n",
        "  ##################################################################\n",
        "  block1       = Conv2D(F1, (1, kernelLength), padding = 'same',\n",
        "                                  input_shape = (1, Chans, Samples),\n",
        "                                  use_bias = False)(input1)\n",
        "  block1       = BatchNormalization(axis = 1)(block1)\n",
        "  block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
        "                                  depth_multiplier = D,\n",
        "                                  depthwise_constraint = max_norm(1.))(block1)\n",
        "  block1       = BatchNormalization(axis = 1)(block1)\n",
        "  block1       = Activation('elu')(block1)\n",
        "  block1       = AveragePooling2D((1, 4))(block1)\n",
        "  block1       = dropoutType(dropoutRate)(block1)\n",
        "  \n",
        "  block2       = SeparableConv2D(F2, (1, 16),\n",
        "                                  use_bias = False, padding = 'same')(block1)\n",
        "  block2       = BatchNormalization(axis = 1)(block2)\n",
        "  block2       = Activation('elu')(block2)\n",
        "  block2       = AveragePooling2D((1, 8))(block2)\n",
        "  block2       = dropoutType(dropoutRate)(block2)\n",
        "      \n",
        "  flatten      = Flatten(name = 'flatten')(block2)\n",
        "  \n",
        "  dense        = Dense(nb_classes, name = 'dense', \n",
        "                        kernel_constraint = max_norm(norm_rate))(flatten)\n",
        "  softmax      = Activation('softmax', name = 'softmax')(dense)\n",
        "  \n",
        "  model        = Model(inputs=input1, outputs=softmax)\n",
        "  if optimizer_type == 'Adam':\n",
        "    optimizer = Adam(learning_rate = lr)\n",
        "  if optimizer_type == 'Adamax':\n",
        "    optimizer = Adamax(learning_rate = lr)\n",
        "  if optimizer_type == 'AdamW':\n",
        "    optimizer = AdamW(learning_rate = lr)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
        "  return model\n",
        "####################################################################################################\n",
        "def TactileNet(nb_classes=2, Chans = 19, Samples = 512, kernLength = 16,\n",
        "               F1 = 64, D=4, dropoutRate = 0.5,dropoutType = 'Dropout',\n",
        "               optimizer_type = 'Adam', lr=0.001, **kwargs):\n",
        "\n",
        "\n",
        "  if dropoutType == 'SpatialDropout2D':\n",
        "      dropoutType = SpatialDropout2D\n",
        "  elif dropoutType == 'Dropout':\n",
        "      dropoutType = Dropout\n",
        "  else:\n",
        "      raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
        "                        'or Dropout, passed as a string.')\n",
        "  #EEGNet alike part\n",
        "  input1       = Input(shape = (1, Chans, Samples))\n",
        "  block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
        "                                  input_shape = (1, Chans, Samples),\n",
        "                                  use_bias = False)(input1)\n",
        "  block1       = BatchNormalization(axis = 1 ,trainable = True)(block1)\n",
        "  block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
        "                                  depth_multiplier = D,\n",
        "                                  depthwise_constraint = max_norm(1.))(block1)\n",
        "  block1       = BatchNormalization( axis = 1, trainable = True)(block1)\n",
        "  block1       = Activation('elu')(block1)\n",
        "  block1       = AveragePooling2D((1, 2))(block1)\n",
        "  block1       = dropoutType(dropoutRate)(block1)\n",
        "\n",
        "  ###############################################\n",
        "  #first tower\n",
        "  sub_block1   = Conv2D(64, (1, 1), padding = 'same',use_bias = False)(block1)\n",
        "  sub_block1   = SeparableConv2D(128, (1, 128), padding = 'same',use_bias = False)(sub_block1)\n",
        "  sub_block1   = AveragePooling2D((1, 2), padding = 'same')(sub_block1)\n",
        "  #second tower\n",
        "  sub_block2   = Conv2D(16, (1, 1), padding = 'same',use_bias = False)(block1)\n",
        "  sub_block2   = SeparableConv2D(32, (1, 256), padding = 'same',use_bias = False)(sub_block2)\n",
        "  sub_block2  = AveragePooling2D((1, 2), padding = 'same')(sub_block2)\n",
        "  #third tower\n",
        "  sub_block3   = Conv2D(64, (1, 1), padding = 'same', strides=(1,2), use_bias = False)(block1)\n",
        "  #forth tower\n",
        "  sub_block4   = AveragePooling2D((1, 2), padding = 'same')(block1)\n",
        "  sub_block4   = Conv2D(32, (1, 1), padding = 'same',use_bias = False)(sub_block4)\n",
        "  #concatenation\n",
        "  concat       = concatenate([sub_block1, sub_block2, sub_block4, sub_block3],axis=1)\n",
        "  \n",
        "  #last tower\n",
        "  block2       = BatchNormalization( axis = 1, trainable = True)(concat)\n",
        "  block2       = Activation('elu')(block2)\n",
        "  #SENEt block\n",
        "  squeeze1     = GlobalAveragePooling2D()(block2)\n",
        "  excitation1  = Dense(16, activation='relu')(squeeze1)\n",
        "  excitation1  = Dense(256, activation='sigmoid')(excitation1)\n",
        "  block2       = Permute(dims=(2,3,1))(block2)\n",
        "  excitation1  = multiply([block2, excitation1])\n",
        "  excitation1  = Permute(dims=(3,1,2))(excitation1)\n",
        "\n",
        "  block2       = SeparableConv2D(256, (1, 64), padding = 'same',use_bias = False)(excitation1)\n",
        "  block2       = BatchNormalization( axis = 1, trainable = True)(block2)\n",
        "  block2       = Activation('elu')(block2)\n",
        "  #SENEt block\n",
        "  squeeze2     = GlobalAveragePooling2D()(block2)\n",
        "  excitation2  = Dense(16, activation='relu')(squeeze2)\n",
        "  excitation2  = Dense(256, activation='sigmoid')(excitation2)\n",
        "  block2       = Permute(dims=(2,3,1))(block2)\n",
        "  excitation2  = multiply([block2, excitation2])\n",
        "  excitation2  = Permute(dims=(3,1,2))(excitation2)\n",
        "\n",
        "  block2       = dropoutType(dropoutRate)(excitation2)\n",
        "\n",
        "  GB           = GlobalAveragePooling2D()(block2)\n",
        "  dense        = Dense(nb_classes, name = 'dense')(GB)\n",
        "  softmax      = Activation('softmax', name = 'softmax')(dense)\n",
        "  if optimizer_type == 'Adam':\n",
        "    optimizer = Adam(learning_rate = lr)\n",
        "  if optimizer_type == 'Adamax':\n",
        "    optimizer = Adamax(learning_rate = lr)\n",
        "  if optimizer_type == 'AdamW':\n",
        "    optimizer = AdamW(learning_rate = lr)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics = ['accuracy'])\n",
        "  return model\n",
        "\n",
        "  return Model(inputs=input1, outputs=softmax)\n"
      ],
      "metadata": {
        "id": "HwIQOfn9qWgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating the accuracy and F-measure for each subject**"
      ],
      "metadata": {
        "id": "snjDtnyiBG2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def subject_classification(y_true, y_pred, group, calculate_type = 'max_vote'):  \n",
        "  \"\"\"\n",
        "  y_pred should be the output of 'model.predict' using 2 nodes in the dense layer and softmax activation.\n",
        "  y_true should be in categorical mode. \n",
        "  \"\"\"\n",
        "  from pyriemann.utils.viz import plot_confusion_matrix\n",
        "  from sklearn.metrics import fbeta_score\n",
        "\n",
        "  #Categorical to normal labeling\n",
        "  y_true = y_true.argmax(axis=-1)\n",
        "  probability = np.array(y_pred)\n",
        "  prediction = y_pred.argmax(axis = -1)\n",
        "  max_vote = []\n",
        "  subject_traget = []\n",
        "  j = 0\n",
        "  unique, counts = np.unique(group, return_counts=True)\n",
        "  mean_ = np.zeros([len(unique),2], dtype='float32')\n",
        "  for i in range(len(unique)):\n",
        "    for k in range(2):\n",
        "      mean_[i][k] = np.mean(probability[j:j+counts[i]-1,k])\n",
        "    c = np.bincount(prediction[j:j+counts[i]-1])\n",
        "    max_vote.append(np.argmax(c))\n",
        "    subject_traget.append(y_true[j])\n",
        "    j = j + counts[i]\n",
        "  mean_            = mean_.argmax(axis = -1)\n",
        "  max_vote         = np.array(max_vote)\n",
        "  subject_traget   = np.array(subject_traget)\n",
        "  f2_max_vote      = fbeta_score(subject_traget, max_vote, beta=0.5, average='binary')\n",
        "  f2_mean          = fbeta_score(subject_traget, mean_, beta=0.5, average='binary')\n",
        "  acc_max_vote     = np.mean(max_vote == subject_traget)\n",
        "  acc_mean         = np.mean(mean_ == subject_traget)\n",
        "  if calculate_type == 'max_vote':\n",
        "    names          = ['ADHD','Control']\n",
        "    plt.figure(0)\n",
        "    plot_confusion_matrix(subject_traget, max_vote, names, title = 'Max Vote Type')\n",
        "    return acc_max_vote, f2_max_vote\n",
        "  elif calculate_type == 'mean':\n",
        "    names        = ['ADHD','Control']\n",
        "    plt.figure(0)\n",
        "    plot_confusion_matrix(subject_traget, mean_, names, title = 'Mean Type')\n",
        "    return acc_mean, f2_mean\n",
        "  else:\n",
        "    raise ValueError('You have NOT entered an accurate type!')"
      ],
      "metadata": {
        "id": "MNQjhnu5jstz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_classification(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  y_pred should be the output of 'model.predict' using 2 nodes in the dense layer and softmax activation.\n",
        "  y_true should be in categorical mode. \n",
        "  \"\"\"\n",
        "  preds       = y_pred.argmax(axis = -1)  \n",
        "  acc         = np.mean(preds == y_true.argmax(axis=-1))\n",
        "  f2 = fbeta_score(y_true.argmax(axis=-1), preds, beta=0.5, average='binary') \n",
        "  return acc, f2\n"
      ],
      "metadata": {
        "id": "zF72InbpjtME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating the class-weight**"
      ],
      "metadata": {
        "id": "omizpXBCBIh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ClassWeightSoftmax(y):\n",
        "  class_weights = compute_class_weight(class_weight = \"balanced\",classes = np.unique(Y_train), y = Y_train)\n",
        "  class_weights = dict(zip(np.unique(Y_train), class_weights))\n",
        "  class_weights[0] = int(10*round(class_weights[0],1))\n",
        "  class_weights[1] = int(10*round(class_weights[1],1))\n",
        "  class_weight = [{0: 1, 1: class_weights[0]}, {0: 1, 1: class_weights[1]}]\n",
        "  print(\"The Class Weight is:\",class_weight)\n",
        "  return class_weight"
      ],
      "metadata": {
        "id": "JPYdvEF7jwrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data\n",
        "import numpy as np\n",
        "X = np.load('X.npy')\n",
        "Y = np.load('Y.npy')\n",
        "\n",
        "print(\"X Shape:\",X.shape)\n",
        "print(\"Y shape:\",Y.shape)\n",
        "print(Y)\n",
        "import scipy.io\n",
        "SegmentPerSubject = scipy.io.loadmat('SegmentPerSubject', mat_dtype=True)\n",
        "SegmentPerSubject = SegmentPerSubject['SegmentPerSubject']\n",
        "SegmentPerSubject = np.array(SegmentPerSubject)\n",
        "SegmentPerSubject = SegmentPerSubject.transpose()\n",
        "print(\"shape Segments:\", SegmentPerSubject.shape)\n",
        "\n",
        "Group =[]\n",
        "for i in range(SegmentPerSubject.shape[0]):\n",
        "  for j in range(int(SegmentPerSubject[i])):\n",
        "    Group.append(i)\n",
        "Group = np.array(Group)\n",
        "Group = np.expand_dims(Group, axis=1)\n",
        "print(Group)\n",
        "print(\"Group shape is:\",Group.shape)\n",
        "\n",
        "# Data Preparation(Spliting the data to 10 fold and pich one of them as the test se)\n",
        "group_kfold1 = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=2023)\n",
        "del X,Y,d_test, split_test, Group, group_kfold1\n",
        "# Converting the labels to categirical\n",
        "Y_test  = np.expand_dims(Y_test,axis=1)\n",
        "Y_test  = np_utils.to_categorical(Y_test)\n",
        "Y_train  = np.expand_dims(Y_train,axis=1)\n",
        "Y_train  = np_utils.to_categorical(Y_train)\n",
        "# initiating the model\n",
        "model = TactileNet()\n",
        "# Fitting the model\n",
        "fit  = model.fit(X_train, Y_train,verbose = 2,shuffle=True, epochs=20,batch_size=32,validation_data=(X_test, Y_test))\n",
        "### Calculating Sample accuracy ###\n",
        "test_predict = model.predict(X_test)\n",
        "test_sub_acc,test_sub_f2 = subject_classification(Y_test, test_predict, Group_test, calculate_type = 'max_vote')\n",
        "test_sam_acc,test_sam_f2 = sample_classification(Y_test, test_predict)\n",
        "################################################\n",
        "print(\"test_sub_acc\",test_sub_acc)\n",
        "print(\"test_sub_f2\",test_sub_f2)\n",
        "print(\"test_sam_acc\",test_sam_acc)\n",
        "print(\"test_sam_f2\",test_sam_f2)\n",
        "###############################################\n",
        "train_loss, train_acc = model.evaluate(X_train,Y_train)\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aHSGgFUTtO89",
        "outputId": "521f4be7-4b47-41a7-add0-e445e7e8aadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Shape: (4173, 1, 19, 512)\n",
            "Y shape: (4173,)\n",
            "[0 0 0 ... 1 1 1]\n",
            "shape Segments: (121, 1)\n",
            "[[  0]\n",
            " [  0]\n",
            " [  0]\n",
            " ...\n",
            " [120]\n",
            " [120]\n",
            " [120]]\n",
            "Group shape is: (4173, 1)\n",
            "Epoch 1/20\n",
            "116/116 - 6s - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.0559 - val_accuracy: 0.9707 - 6s/epoch - 52ms/step\n",
            "Epoch 2/20\n",
            "116/116 - 4s - loss: 0.0094 - accuracy: 0.9959 - val_loss: 0.0120 - val_accuracy: 0.9958 - 4s/epoch - 35ms/step\n",
            "Epoch 3/20\n",
            "116/116 - 4s - loss: 0.0254 - accuracy: 0.9932 - val_loss: 0.0051 - val_accuracy: 0.9979 - 4s/epoch - 35ms/step\n",
            "Epoch 4/20\n",
            "116/116 - 4s - loss: 0.0185 - accuracy: 0.9932 - val_loss: 0.0213 - val_accuracy: 0.9937 - 4s/epoch - 33ms/step\n",
            "Epoch 5/20\n",
            "116/116 - 4s - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0013 - val_accuracy: 1.0000 - 4s/epoch - 32ms/step\n",
            "Epoch 6/20\n",
            "116/116 - 4s - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.0217 - val_accuracy: 0.9916 - 4s/epoch - 32ms/step\n",
            "Epoch 7/20\n",
            "116/116 - 4s - loss: 0.0085 - accuracy: 0.9962 - val_loss: 0.0298 - val_accuracy: 0.9874 - 4s/epoch - 31ms/step\n",
            "Epoch 8/20\n",
            "116/116 - 4s - loss: 0.0032 - accuracy: 0.9986 - val_loss: 0.0149 - val_accuracy: 0.9958 - 4s/epoch - 31ms/step\n",
            "Epoch 9/20\n",
            "116/116 - 4s - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0051 - val_accuracy: 0.9979 - 4s/epoch - 31ms/step\n",
            "Epoch 10/20\n",
            "116/116 - 4s - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.2840 - val_accuracy: 0.9310 - 4s/epoch - 31ms/step\n",
            "Epoch 11/20\n",
            "116/116 - 4s - loss: 0.0089 - accuracy: 0.9962 - val_loss: 0.0037 - val_accuracy: 0.9979 - 4s/epoch - 32ms/step\n",
            "Epoch 12/20\n",
            "116/116 - 4s - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.1135 - val_accuracy: 0.9519 - 4s/epoch - 32ms/step\n",
            "Epoch 13/20\n",
            "116/116 - 4s - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.1390 - val_accuracy: 0.9372 - 4s/epoch - 32ms/step\n",
            "Epoch 14/20\n",
            "116/116 - 4s - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0038 - val_accuracy: 0.9979 - 4s/epoch - 32ms/step\n",
            "Epoch 15/20\n",
            "116/116 - 4s - loss: 0.0152 - accuracy: 0.9957 - val_loss: 1.1822 - val_accuracy: 0.6590 - 4s/epoch - 32ms/step\n",
            "Epoch 16/20\n",
            "116/116 - 4s - loss: 0.0043 - accuracy: 0.9981 - val_loss: 0.0447 - val_accuracy: 0.9833 - 4s/epoch - 32ms/step\n",
            "Epoch 17/20\n",
            "116/116 - 4s - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0034 - val_accuracy: 1.0000 - 4s/epoch - 33ms/step\n",
            "Epoch 18/20\n",
            "116/116 - 4s - loss: 0.0149 - accuracy: 0.9943 - val_loss: 5.2036e-04 - val_accuracy: 1.0000 - 4s/epoch - 32ms/step\n",
            "Epoch 19/20\n",
            "116/116 - 4s - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 1.0000 - 4s/epoch - 32ms/step\n",
            "Epoch 20/20\n",
            "116/116 - 4s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0060 - val_accuracy: 0.9979 - 4s/epoch - 33ms/step\n",
            "15/15 [==============================] - 0s 6ms/step\n",
            "test_sub_acc 1.0\n",
            "test_sub_f2 1.0\n",
            "test_sam_acc 0.997907949790795\n",
            "test_sam_f2 0.9958071278825996\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}